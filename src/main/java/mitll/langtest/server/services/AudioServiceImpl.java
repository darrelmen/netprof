/*
 *
 * DISTRIBUTION STATEMENT C. Distribution authorized to U.S. Government Agencies
 * and their contractors; 2015. Other request for this document shall be referred
 * to DLIFLC.
 *
 * WARNING: This document may contain technical data whose export is restricted
 * by the Arms Export Control Act (AECA) or the Export Administration Act (EAA).
 * Transfer of this data by any means to a non-US person who is not eligible to
 * obtain export-controlled data is prohibited. By accepting this data, the consignee
 * agrees to honor the requirements of the AECA and EAA. DESTRUCTION NOTICE: For
 * unclassified, limited distribution documents, destroy by any method that will
 * prevent disclosure of the contents or reconstruction of the document.
 *
 * This material is based upon work supported under Air Force Contract No.
 * FA8721-05-C-0002 and/or FA8702-15-D-0001. Any opinions, findings, conclusions
 * or recommendations expressed in this material are those of the author(s) and
 * do not necessarily reflect the views of the U.S. Air Force.
 *
 * Â© 2015 Massachusetts Institute of Technology.
 *
 * The software/firmware is provided to you on an As-Is basis
 *
 * Delivered to the US Government with Unlimited Rights, as defined in DFARS
 * Part 252.227-7013 or 7014 (Feb 2014). Notwithstanding any copyright notice,
 * U.S. Government rights in this work are defined by DFARS 252.227-7013 or
 * DFARS 252.227-7014 as detailed above. Use of this work other than as specifically
 * authorized by the U.S. Government may violate any copyrights that exist in this work.
 *
 *
 */

package mitll.langtest.server.services;

import audio.image.ImageType;
import audio.imagewriter.SimpleImageWriter;
import mitll.langtest.client.AudioTag;
import mitll.langtest.client.services.AudioService;
import mitll.langtest.server.audio.*;
import mitll.langtest.server.database.AnswerInfo;
import mitll.langtest.server.database.audio.AudioInfo;
import mitll.langtest.server.database.custom.IUserListManager;
import mitll.langtest.server.database.exercise.Project;
import mitll.langtest.shared.answer.AudioAnswer;
import mitll.langtest.shared.answer.AudioType;
import mitll.langtest.shared.exercise.*;
import mitll.langtest.shared.image.ImageResponse;
import mitll.langtest.shared.scoring.AudioContext;
import mitll.langtest.shared.scoring.ImageOptions;
import mitll.langtest.shared.user.User;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;

import java.io.File;
import java.util.Collection;
import java.util.HashSet;
import java.util.List;
import java.util.Set;
import java.util.stream.Collectors;

/**
 * does image generation here too - since it's done from a file.
 */
@SuppressWarnings("serial")
public class AudioServiceImpl extends MyRemoteServiceServlet implements AudioService {
  private static final Logger logger = LogManager.getLogger(AudioServiceImpl.class);

  private static final String WAV1 = "wav";
  private static final String WAV = ".wav";
  private static final String MP3 = ".mp3";
  private static final int MP3_LENGTH = MP3.length();

  private static final boolean DEBUG = false;
  private static final boolean WARN_MISSING_FILE = false;
  public static final int WARN_THRESH = 100;

  private AudioConversion audioConversion;
  private PathWriter pathWriter;

  @Override
  public void init() {
    super.init();
    audioConversion = new AudioConversion(serverProps);
    pathWriter = new PathWriter(serverProps);
  }

  /**
   * Record an answer entry in the database.<br></br>
   * Write the posted data to a wav and an mp3 file (since all the browser audio works with mp3).
   * <p>
   * A side effect is to set the first state to UNSET if it was APPROVED
   * and to set the second state (not really used right now) to RECORDED
   * <p>
   * <p>
   * Wade has observed that audio normalization really messes up the ASR -- silence doesn't appear as silence after you multiply
   * the signal.  Also, the user doesn't get feedback that their mic gain is too high/too low or that they
   * are speaking too softly or too loudly
   * <p>
   * Client references below:
   *
   * @param base64EncodedString generated by flash on the client
   * @param recordedWithFlash   mark if we recorded it using flash recorder or webrtc
   * @param deviceType
   * @param device
   * @param doFlashcard         true if called from practice (flashcard) and we want to do decode and not align
   * @param recordInResults     if true, record in results table -- only when recording in a learn or practice tab
   * @param addToAudioTable     if true, add to audio table -- only when recording reference audio for an item.
   * @param allowAlternates
   * @return AudioAnswer object with information about the audio on the server, including if audio is valid (not too short, etc.)
   * @see mitll.langtest.client.scoring.PostAudioRecordButton#stopRecording
   * @see mitll.langtest.client.recorder.RecordButtonPanel#stopRecording
   */
  @Override
  public AudioAnswer writeAudioFile(String base64EncodedString,
                                    AudioContext audioContext,

                                    boolean recordedWithFlash,
                                    String deviceType,
                                    String device,

                                    boolean doFlashcard,
                                    boolean recordInResults,
                                    boolean addToAudioTable,
                                    boolean allowAlternates) {
    AudioFileHelper audioFileHelper = getAudioFileHelper();

    int exerciseID = audioContext.getExid();
    boolean isExistingExercise = exerciseID > 0;

    logger.info("writeAudioFile got " +
        "\n\trequest         " + audioContext +
        "\n\tdo flashcard    " + doFlashcard +
        "\n\trecordInResults " + recordInResults +
        "\n\taddToAudioTable " + addToAudioTable +
        "\n\tallowAlternates " + allowAlternates +
        "\n\tpayload bytes   " + base64EncodedString.length());

    if (addToAudioTable && !recordInResults) { // we have a foreign key from audio into result table - must record in results
      recordInResults = true;
    }
    boolean amas = serverProps.isAMAS();

    CommonExercise commonExercise = amas || isExistingExercise ?
        db.getCustomOrPredefExercise(getProjectID(), exerciseID) :
        db.getUserExerciseDAO().getTemplateExercise(db.getProjectDAO().getDefault());

    int projid = audioContext.getProjid();
    String language = db.getProject(projid).getLanguage();

    if (!isExistingExercise) {
      ((Exercise) commonExercise).setProjectID(projid);
      audioContext.setExid(commonExercise.getID());
    }

    CommonShell exercise1 = amas ? db.getAMASExercise(exerciseID) : commonExercise;

    if (exercise1 == null && isExistingExercise) {
      logger.warn("writeAudioFile " + getLanguage() + " : couldn't find exerciseID with id '" + exerciseID + "'");
    }
    String audioTranscript = getAudioTranscript(audioContext.getAudioType(), commonExercise);
    AnswerInfo.RecordingInfo recordingInfo = new AnswerInfo.RecordingInfo("", "", deviceType, device, recordedWithFlash, audioTranscript);

    DecoderOptions options = new DecoderOptions()
        .setRecordInResults(recordInResults)
        .setDoFlashcard(doFlashcard)
        .setRefRecording(addToAudioTable)
        .setAllowAlternates(allowAlternates);

    logger.info("writeAudioFile recording info " + recordingInfo);

    AudioAnswer audioAnswer = amas ?
        audioFileHelper.writeAMASAudioFile(base64EncodedString, db.getAMASExercise(exerciseID), audioContext, recordingInfo) :
        audioFileHelper.writeAudioFile(
            base64EncodedString,
            exercise1,
            audioContext,
            recordingInfo,

            options);

    logger.info("writeAudioFile recording audioAnswer transcript '" + audioAnswer.getTranscript() + "'");

    int user = audioContext.getUserid();
    if (addToAudioTable && audioAnswer.isValid()) {
      audioAnswer.setAudioAttribute(addToAudioTable(user, audioContext.getAudioType(), commonExercise, exerciseID, audioAnswer));
    } //else {
    // So Wade has observed that this really messes up the ASR -- silence doesn't appear as silence after you multiply
    // the signal.  Also, the user doesn't get feedback that their mic gain is too high/too low or that they
    // are speaking too softly or too loudly.

    // normalizeLevel(audioAnswer);
    // }

    try {
      if (!audioAnswer.isValid() && audioAnswer.getDurationInMillis() == 0) {
        logger.warn("huh? got zero length recording " + user + " " + exerciseID);
        logEvent("audioRecording", "writeAudioFile", "" + exerciseID, "Writing audio - got zero duration!", user, "unknown", device);
      } else {
        ensureCompressedAudio(user, commonExercise, audioAnswer.getPath(), audioContext.getAudioType(), language);
        logger.info("wrote compressed...");
      }
    } catch (Exception e) {
      logger.error("Got " + e, e);
    }

    return audioAnswer;
  }

  /**
   * Kick off a thread to do this... so we can return.
   */
  public void ensureAllAudio() {
    new Thread(new Runnable() {
      @Override
      public void run() {
        db.getProjects().forEach(project -> ensureAudio(project.getID()));
      }
    }).start();
  }

  @Override
  public void checkAudio(int projectid) {
    Project project = db.getProject(projectid);
    logger.info("0 checkAudio - for project " + projectid + " " + project);
    long then = System.currentTimeMillis();
    db.getAudioDAO().makeSureAudioIsThere(projectid, project.getLanguage(), true);
    long now = System.currentTimeMillis();
    if (now - then > WARN_THRESH) logger.info("1 checkAudio - took " + (now - then) + " millis to check audio");

    ensureAudio(projectid);
  }

  /**
   * This could take a long time - lots of files, shell out for each one...
   * @param projectid
   */
  private void ensureAudio(int projectid) {
    long now = System.currentTimeMillis();
    long then;
    then = now;
    List<CommonExercise> exercises = db.getExercises(projectid);
    now = System.currentTimeMillis();
    if (now - then > WARN_THRESH) logger.info("2 checkAudio - took " + (now - then) + " millis to get exercises");

    ensureAudioForExercises( exercises);
  }

  public void ensureAudioForIDs(int projid, Collection<Integer> ids) {
    ensureAudioForExercises(ids.stream().map(id -> db.getCustomOrPredefExercise(projid,id)).collect(Collectors.toList()));
  }

  private void ensureAudioForExercises(  List<CommonExercise> exercises) {
    long now = System.currentTimeMillis();
    long then;
    String language = getLanguage();
    then = now;
    db.getAudioDAO().attachAudioToExercises(exercises, language);
    now = System.currentTimeMillis();
    if (now - then > WARN_THRESH) logger.info("3  checkAudio - took " + (now - then) + " millis to attach audio");

    then = now;
    int c = 0;
    int success = 0;
    for (CommonExercise e : exercises) {
      if (e != null) {
        for (AudioAttribute audioAttribute : e.getAudioAttributes()) {
          c++;
          if (c < 10) {
//            logger.info("checkAudio e.g. ensure audio for " + audioAttribute + " on " + e);
          }
          try {
            boolean didit = ensureCompressedAudio(
                audioAttribute.getUserid(),
                e,
                audioAttribute.getAudioRef(),
                audioAttribute.getAudioType(),
                language);
            if (didit) success++;
            if (c % 1000 == 0) logger.debug("checkAudio checked " + c + ", success = " + success);
          } catch (Exception e1) {
            logger.warn("Got " +e1 + " for exercise " +e.getID() + " : " + audioAttribute.getAudioRef());
          }
        }
      }
    }
    now = System.currentTimeMillis();
    if (now - then > WARN_THRESH) {
      logger.info("4 checkAudio - took " + (now - then) + " millis to ensure ogg and mp3 for " + c + " attributes for " +
          exercises.size() + " exercises, " +
          success + " files successful");
    }
  }


  /**
   * @param user
   * @param commonShell
   * @param path
   * @param audioType
   * @param language
   * @see #writeAudioFile
   */
  private boolean ensureCompressedAudio(int user,
                                        CommonExercise commonShell,
                                        String path,
                                        AudioType audioType,
                                        String language) {
    if (checkedExists.contains(path)) return true;

    String userID = getUserID(user);
    if (userID == null) {
      logger.warn("ensureCompressedEquivalent huh? no user for " + user);
    }

    boolean noExerciseYet = commonShell == null;
    String title   = noExerciseYet ? "unknown" : commonShell.getForeignLanguage();
    String comment = noExerciseYet ? "unknown" : commonShell.getEnglish();
    if (audioType.equals(AudioAttribute.CONTEXT_AUDIO_TYPE) && !noExerciseYet) {
      if (commonShell.hasContext()) {
        CommonExercise contextSentence = commonShell.getDirectlyRelated().iterator().next();
        title = contextSentence.getForeignLanguage();
        comment = contextSentence.getEnglish();
      }
    }

    boolean b = ensureMP3(path, new TrackInfo(title, userID, comment, language));
    if (b) checkedExists.add(path);
    return b;
  }

  private Set<String> checkedExists = new HashSet<>();

  /**
   * for both audio in answers and best audio -- could be more efficient...
   *
   * @param wavFile
   * @param trackInfo
   * @return true if mp3 file exists
   * @seex #ensureMP3s(CommonExercise, String)
   * @see #writeAudioFile
   */
  private boolean ensureMP3(String wavFile, TrackInfo trackInfo) {

    String parent = serverProps.getAnswerDir();
    if (wavFile != null) {
      if (DEBUG) logger.debug("ensureMP3 : trying " + wavFile);
      // File test = new File(parent + File.separator + language, wavFile);
      File test = new File(wavFile);
      if (!test.exists()) {
        if (WARN_MISSING_FILE) {
          logger.warn("ensureMP3 : can't find " + test.getAbsolutePath());// + " under " + parent + " trying config... ");
        }
        parent = serverProps.getAudioBaseDir();// + File.separator + language;
        if (DEBUG)
          logger.warn("ensureMP3 : trying " + wavFile + " under " + parent);// + " under " + parent + " trying config... ");
      }

/*      if (!audioConversion.exists(wavFile, parent)) {// && wavFile.contains("1310")) {
        if (WARN_MISSING_FILE && spew++ < 10) {
          logger.error("ensureMP3 : can't find " + wavFile + " under " + parent + " for " + title + " " + artist);
        }
      }*/

      String s = audioConversion.ensureWriteMP3(parent, wavFile, false, trackInfo);
      boolean isMissing = s.equals(AudioConversion.FILE_MISSING);
      if (isMissing) {
        if (spew++ < 10 || spew % 1000 == 0) {
          logger.error("ensureMP3 : (count = " + spew + ")" +
              " can't find " + wavFile + " under " + parent + " for " + trackInfo);
        }
      }
      return !isMissing;
    }
    return false;
  }

  private int spew = 0;

  private String getUserID(int user) {
    User userBy = getUserBy(user);
    return userBy == null ? "" + user : userBy.getUserID();
  }

  private User getUserBy(int id) {
    return db.getUserDAO().getUserWhere(id);
  }

  public void logEvent(String id, String widgetType, String exid, String context, int userid, String hitID, String device) {
    try {
      db.logEvent(id, widgetType, exid, context, userid, device);
    } catch (Exception e) {
      logger.error("got " + e, e);
    }
  }

  /**
   * Remember this audio as reference audio for this exercise, and possibly clear the APRROVED (inspected) state
   * on the exercise indicating it needs to be inspected again (we've added new audio).
   * <p>
   * Don't return a path to the normalized audio, since this doesn't let the recorder have feedback about how soft
   * or loud they are : https://gh.ll.mit.edu/DLI-LTEA/Development/issues/601
   *
   * @param user        who recorded audio
   * @param audioType   regular or slow
   * @param exercise1   for which exercise - how could this be null?
   * @param exerciseID  perhaps sometimes we want to override the exercise id?
   * @param audioAnswer holds the path of the temporary recorded file
   * @return AudioAttribute that represents the audio that has been added to the exercise
   * @see #writeAudioFile
   */
  private AudioAttribute addToAudioTable(int user,
                                         AudioType audioType,
                                         CommonExercise exercise1,
                                         int exerciseID,
                                         AudioAnswer audioAnswer) {
    boolean noExistingExercise = exercise1 == null;
    int idToUse = noExistingExercise ? exerciseID : exercise1.getID();
    int projid = noExistingExercise ? -1 : exercise1.getProjectID();
    String audioTranscript = audioAnswer.getTranscript();
    String language = db.getProject(projid).getLanguage();
    //   logger.debug("addToAudioTable user " + user + " ex " + exerciseID + " for " + audioType + " path before " + audioAnswer.getPath());

    File absoluteFile = pathHelper.getAbsoluteAudioFile(audioAnswer.getPath());
    boolean isContext = audioType == AudioType.CONTEXT_REGULAR || audioType == AudioType.CONTEXT_SLOW;
    String context = noExistingExercise ? "" :
        isContext ? exercise1.getDirectlyRelated().iterator().next().getEnglish() : exercise1.getEnglish();

    if (!absoluteFile.exists()) logger.error("addToAudioTable huh? no file at " + absoluteFile.getAbsolutePath());
    String permanentAudioPath = pathWriter.
        getPermanentAudioPath(
            absoluteFile,
            getPermanentName(user, audioType),
            true,
            language,
            idToUse,
            //audioTranscript,
            serverProps,
            new TrackInfo(audioTranscript, getArtist(user), context, language));

    AudioAttribute audioAttribute = null;
    try {
      AudioInfo info = new AudioInfo(user, idToUse, projid, audioType, permanentAudioPath, System.currentTimeMillis(),
          audioAnswer.getDurationInMillis(), audioTranscript, (float) audioAnswer.getDynamicRange(), audioAnswer.getResultID());

      audioAttribute = db.getAudioDAO().addOrUpdate(info);

      audioAnswer.setPath(audioAttribute.getAudioRef());
      logger.debug("addToAudioTable" +
          "\n\tuser " + user +
          "\n\tex " + exerciseID + "/" + idToUse +
          "\n\tfor " + audioType +
          "\n\taudio answer has " + audioAttribute);

      // what state should we mark recorded audio?
      setExerciseState(idToUse, user, exercise1);
    } catch (Exception e) {
      logger.error("got " + e, e);
    }
    return audioAttribute;
  }

  private String getAudioTranscript(AudioType audioType, CommonExercise exercise1) {
    return exercise1 == null ? "" :
        audioType.equals(AudioAttribute.CONTEXT_AUDIO_TYPE) ? exercise1.getContext() : exercise1.getForeignLanguage();
  }

  private String getPermanentName(int user, AudioType audioType) {
    return audioType.toString() + "_" + System.currentTimeMillis() + "_by_" + user + ".wav";
  }

  private String getArtist(int user) {
    User userWhere = db.getUserDAO().getUserWhere(user);
    return userWhere == null ? "" + user : userWhere.getUserID();
  }

  private File getAbsoluteFile(String path) {
    return pathHelper.getAbsoluteFile(path);
  }

  /**
   * Only change APPROVED to UNSET.
   *
   * @param exercise
   * @param user
   * @param exercise1
   */
  private void setExerciseState(int exercise, int user, Shell exercise1) {
    if (exercise1 != null) {
      IUserListManager userListManager = getUserListManager();
      STATE currentState = userListManager.getCurrentState(exercise);
      if (currentState == STATE.APPROVED) { // clear approved on new audio -- we need to review it again
        userListManager.setState(exercise1, STATE.UNSET, user);
      }
      userListManager.setSecondState(exercise1, STATE.RECORDED, user);
    }
  }

  /*
  private AudioFileHelper getAudioFileHelper() {
    if (serverProps.isAMAS()) {
      return audioFileHelper;
    } else {
      Project project = getProject();
      if (project == null) {
        logger.warn("getAudioFileHelper no current project???");
        return null;
      }
      return project.getAudioFileHelper();
    }
  }
*/

  /**
   * Get an image of desired dimensions for the audio file - only for Waveform and spectrogram.
   * Also returns the audio file duration -- so we can deal with the difference in length between mp3 and wav
   * versions of the same audio file.  (The browser soundmanager plays mp3 and reports audio offsets into
   * the mp3 file, but all the images are generated from the shorter wav file.)
   * <p>
   * TODO : Worrying about absolute vs relative path is maddening.  Must be a better way!
   *
   * @param reqid
   * @param audioFile
   * @param imageType
   * @param imageOptions
   * @param exerciseID
   * @return path to an image file
   * @see mitll.langtest.client.scoring.AudioPanel#getImageURLForAudio
   */
  public ImageResponse getImageForAudioFile(int reqid,
                                            String audioFile,
                                            String imageType,
                                            ImageOptions imageOptions,
                                            String exerciseID) {
    if (audioFile.isEmpty())
      logger.error("getImageForAudioFile huh? audio file is empty for req id " + reqid + " exid " + exerciseID);

    SimpleImageWriter imageWriter = new SimpleImageWriter();

    String wavAudioFile = getWavAudioFile(audioFile);
    File testFile = new File(wavAudioFile);
    if (!testFile.exists() || testFile.length() == 0) {
      if (testFile.length() == 0) logger.error("getImageForAudioFile : huh? " + wavAudioFile + " is empty???");
      return new ImageResponse();
    }
    ImageType imageType1 =
        imageType.equalsIgnoreCase(ImageType.WAVEFORM.toString()) ?
            ImageType.WAVEFORM :
            imageType.equalsIgnoreCase(ImageType.SPECTROGRAM.toString()) ?
                ImageType.SPECTROGRAM : null;
    if (imageType1 == null) {
      logger.error("getImageForAudioFile '" + imageType + "' is unknown?");
      return new ImageResponse(); // success = false!
    }
//    if (DEBUG || true) {
//      logger.debug("getImageForAudioFile : getting images (" + width + " x " + height + ") (" + reqid + ") type " + imageType +
//          " for " + wavAudioFile + "");
//    }

    long then = System.currentTimeMillis();

    String imageOutDir = pathHelper.getImageOutDir();
    File absoluteFile = getAbsoluteFile(imageOutDir);

//    logger.info("getImageForAudioFile imageOutDir " + imageOutDir + " " +absoluteFile + " type " + imageType1);
    String absolutePathToImage = imageWriter.writeImage(
        wavAudioFile,
        absoluteFile.getAbsolutePath(),
        imageOptions.getWidth(), imageOptions.getHeight(), imageType1, exerciseID);
    long now = System.currentTimeMillis();
    long diff = now - then;
    if (diff > WARN_THRESH) {
      logger.debug("getImageForAudioFile : got images " +
          // "(" + width + " x " + height + ")" +
          " (" + reqid + ") type " + imageType +
          " for " + wavAudioFile + " took " + diff + " millis");
    }
    String installPath = pathHelper.getInstallPath();

    String relativeImagePath = absolutePathToImage;
    if (absolutePathToImage.startsWith(installPath)) {
      relativeImagePath = absolutePathToImage.substring(installPath.length());
    } else {
      logger.error("getImageForAudioFile huh? file path " + absolutePathToImage + " doesn't start with " + installPath + "?");
    }

    relativeImagePath = pathHelper.ensureForwardSlashes(relativeImagePath);
    if (relativeImagePath.startsWith("/")) {
      relativeImagePath = relativeImagePath.substring(1);
    }
    String imageURL = relativeImagePath;
    double duration = new AudioCheck(serverProps).getDurationInSeconds(wavAudioFile);
    if (duration == 0) {
      logger.error("huh? " + wavAudioFile + " has zero duration???");
    }
/*
    logger.debug("getImageForAudioFile for" +
        "\n\taudio file " + wavAudioFile +
        "\n\ttype       " + imageType +
        "\n\trel path   " + relativeImagePath +
        "\n\turl        " + imageURL +
        "\n\tduration   " + duration);
*/

    return new ImageResponse(reqid, imageURL, duration);
  }

  /**
   * Here we assume the audioFile path is like
   * <p>
   * bestAudio/spanish/bestAudio/123/regular_xxx.mp3
   * OR answers/spanish/answers/123/regular_xxx.mp3
   *
   * @param audioFile
   * @return
   */
  private String getWavAudioFile(String audioFile) {
    if (audioFile.endsWith("." + AudioTag.COMPRESSED_TYPE) || audioFile.endsWith(MP3)) {
      String wavFile = removeSuffix(audioFile) + WAV;
//      logger.info("getWavAudioFile " + audioFile);
      if (new File(wavFile).exists()) {
        return wavFile;
      } else {
        File test = pathHelper.getAbsoluteAudioFile(wavFile);
        //      logger.info("getWavAudioFile test " + test.getAbsolutePath());
        audioFile = test.exists() ? test.getAbsolutePath() : "FILE_MISSING.wav";//getAudioFileHelper().getWavForMP3(audioFile, );
      }
    }

    return ensureWAV(audioFile);
  }

  private String removeSuffix(String audioFile) {
    return audioFile.substring(0, audioFile.length() - MP3_LENGTH);
  }

  private String ensureWAV(String audioFile) {
    if (!audioFile.endsWith(WAV1)) {
      return audioFile.substring(0, audioFile.length() - MP3_LENGTH) + WAV;
    } else {
      return audioFile;
    }
  }


  public void recalcRefAudio(int projid) {
    Project project = db.getProject(projid);
    logger.info("recalc ref audio on " + project);
    project.recalcRefAudio();
  }
}