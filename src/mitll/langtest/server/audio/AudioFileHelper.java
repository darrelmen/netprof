/*
 * Copyright Â© 2011-2015 Massachusetts Institute of Technology, Lincoln Laboratory
 */

package mitll.langtest.server.audio;

import com.google.common.io.Files;
import mitll.langtest.client.AudioTag;
import mitll.langtest.server.LangTestDatabaseImpl;
import mitll.langtest.server.LogAndNotify;
import mitll.langtest.server.PathHelper;
import mitll.langtest.server.ServerProperties;
import mitll.langtest.server.autocrt.AutoCRT;
import mitll.langtest.server.database.DatabaseImpl;
import mitll.langtest.server.scoring.*;
import mitll.langtest.shared.AudioAnswer;
import mitll.langtest.shared.AudioAttribute;
import mitll.langtest.shared.CommonExercise;
import mitll.langtest.shared.Result;
import mitll.langtest.shared.scoring.PretestScore;
import net.sf.json.JSONObject;
import org.apache.log4j.Logger;

import java.io.File;
import java.text.Collator;
import java.util.*;

/**
 * Created with IntelliJ IDEA.
 * User: GO22670
 * Date: 8/8/13
 * Time: 5:08 PM
 * To change this template use File | Settings | File Templates.
 */
public class AudioFileHelper implements CollationSort, AutoCRTScoring {
  private static final Logger logger = Logger.getLogger(AudioFileHelper.class);
  private static final String POSTED_AUDIO = "postedAudio";
  private static final int MIN_WARN_DUR = 30;
  public static final String REG = "reg";
  public static final String SLOW = "slow";

  private final PathHelper pathHelper;
  private final ServerProperties serverProps;
  private final MP3Support mp3Support;
  private ASR asrScoring;
  private ASRScoring oldschoolScoring;
  private ASRWebserviceScoring webserviceScoring;
  private AutoCRT autoCRT;
  private final DatabaseImpl db;
  private final LogAndNotify logAndNotify;
  private boolean checkedLTS = false;
  private Map<String, Integer> phoneToCount;
  private boolean useOldSchoolServiceOnly = false;

  /**
   * @param pathHelper
   * @param serverProperties
   * @param db
   * @param langTestDatabase
   * @see mitll.langtest.server.ScoreServlet#getAudioFileHelper()
   */
  public AudioFileHelper(PathHelper pathHelper, ServerProperties serverProperties, DatabaseImpl db,
                         LogAndNotify langTestDatabase) {
    this.pathHelper = pathHelper;
    this.serverProps = serverProperties;
    this.db = db;
    this.logAndNotify = langTestDatabase;
    this.useOldSchoolServiceOnly = serverProperties.getOldSchoolService();
    this.mp3Support = new MP3Support(pathHelper, serverProperties);
    makeAutoCRT();
  }

  /**
   * @return
   * @see mitll.langtest.server.scoring.ASRScoring#getCollator
   */
  public Collator getCollator() {
    makeASRScoring();
    return asrScoring.getCollator();
  }

  /**
   * @param exercises
   * @see LangTestDatabaseImpl#getExercises()
   */
  public void checkLTS(List<CommonExercise> exercises) {
    synchronized (this) {
      if (!checkedLTS) {
        checkedLTS = true;
        int count = 0;
        makeASRScoring();

        phoneToCount = new HashMap<String, Integer>();
        for (CommonExercise exercise : exercises) {
          boolean validForeignPhrase = isInDictOrLTS(exercise);
          if (!validForeignPhrase) {
            if (count < 10) {
              logger.error("huh? for " + exercise.getID() + " we can't parse " + exercise.getID() + " " + exercise.getEnglish() + " fl " + exercise.getForeignLanguage());
            }
            count++;
          } else {
            countPhones(exercise);
          }
        }

        if (count > 0) {
          logger.error("huh? out of " + exercises.size() + " LTS fails on " + count);
        }
      }
    }
  }

  private boolean isInDictOrLTS(CommonExercise exercise) {
    return asrScoring.validLTS(exercise.getForeignLanguage());
  }

  private void countPhones(CommonExercise exercise) {
    ASR.PhoneInfo bagOfPhones = asrScoring.getBagOfPhones(exercise.getForeignLanguage());
    exercise.setBagOfPhones(bagOfPhones.getPhoneSet());
    exercise.setFirstPron(bagOfPhones.getFirstPron());

    for (String phone : bagOfPhones.getFirstPron()) {
      Integer integer = getPhoneToCount().get(phone);
      getPhoneToCount().put(phone, integer == null ? 1 : integer + 1);
    }
  }

  /**
   * @param foreignLanguagePhrase
   * @return
   * @see mitll.langtest.server.LangTestDatabaseImpl#isValidForeignPhrase(String)
   */
  public boolean checkLTS(String foreignLanguagePhrase) {
    makeASRScoring();
    return asrScoring.validLTS(foreignLanguagePhrase);
  }

  public SmallVocabDecoder getSmallVocabDecoder() {
    makeASRScoring();
    return asrScoring.getSmallVocabDecoder();
  }

  /**
   * Record an answer entry in the database.<br></br>
   * Write the posted data to a wav and an mp3 file (since all the browser audio works with mp3).
   * <p>
   * Client references:
   *
   * @param base64EncodedString generated by flash on the client
   * @param exerciseID
   * @param exercise1           exerciseID within the plan
   * @param questionID          question within the exerciseID
   * @param user                answering the question
   * @param reqid               request id from the client, so it can potentially throw away out of order responses
   * @param audioType           regular or fast then slow audio recording
   * @param doFlashcard         true if decoding
   * @param recordInResults     true if we should add info to the results table
   * @param recordedWithFlash   true if recorded with Flash, false if via webRTC
   * @param deviceType          browser or iPad or iPhone
   * @param device              browser make and version or iPad unique id
   * @param isRefRecording
   * @param allowAlternates
   * @return URL to audio on server and if audio is valid (not too short, etc.)
   * @see mitll.langtest.client.scoring.PostAudioRecordButton#stopRecording()
   * @see mitll.langtest.client.recorder.RecordButtonPanel#stopRecording()
   * @see LangTestDatabaseImpl#writeAudioFile
   */
  public AudioAnswer writeAudioFile(String base64EncodedString, String exerciseID, CommonExercise exercise1, int questionID,
                                    int user, int reqid, String audioType, boolean doFlashcard,
                                    boolean recordInResults, boolean recordedWithFlash, String deviceType, String device,
                                    boolean isRefRecording, boolean allowAlternates) {
    String wavPath = pathHelper.getLocalPathToAnswer("plan", exerciseID, questionID, user);
    File file = pathHelper.getAbsoluteFile(wavPath);

    long then = System.currentTimeMillis();
    AudioCheck.ValidityAndDur validity = new AudioConversion(serverProps).convertBase64ToAudioFiles(base64EncodedString, file, isRefRecording);
    long now = System.currentTimeMillis();
    long diff = now - then;
    if (diff > MIN_WARN_DUR) {
      logger.debug("took " + diff + " millis to write wav file " + validity.durationInMillis + " millis long");
    }
    boolean isValid = validity.getValidity() == AudioAnswer.Validity.OK || (serverProps.isQuietAudioOK() && validity.getValidity() == AudioAnswer.Validity.TOO_QUIET);
    return getAudioAnswerDecoding(exerciseID, exercise1, questionID, user, reqid, audioType, doFlashcard, recordInResults,
        recordedWithFlash, wavPath, file, validity, isValid
        , deviceType, device,
        allowAlternates, false);
  }

  /**
   * TODO : this is misleading - if doFlashcard is true, it does decoding, otherwise it does *not* do alignment
   *
   * @param exerciseID
   * @param exercise1
   * @param user
   * @param doFlashcard
   * @param wavPath
   * @param file
   * @param deviceType
   * @param device
   * @param score
   * @param reqid
   * @param allowAlternates
   * @return
   * @see mitll.langtest.server.ScoreServlet#getAnswer
   */
  public AudioAnswer getAnswer(String exerciseID, CommonExercise exercise1, int user, boolean doFlashcard, String wavPath,
                               File file, String deviceType, String device, float score, int reqid, boolean allowAlternates) {
    String audioType = doFlashcard ? "flashcard" : "learn";
    AudioCheck.ValidityAndDur validity = new AudioConversion(serverProps).isValid(file, false);
    boolean isValid =
        validity.getValidity() == AudioAnswer.Validity.OK ||
            (serverProps.isQuietAudioOK() && validity.getValidity() == AudioAnswer.Validity.TOO_QUIET);

    return doFlashcard ?
        getAudioAnswerDecoding(exerciseID, exercise1, 0, user, reqid, audioType, doFlashcard, true, true, wavPath, file,
            validity, isValid, deviceType, device, allowAlternates, false) :
        getAudioAnswerAlignment(exerciseID, exercise1, 0, user, reqid, audioType, doFlashcard, true, true, wavPath, file,
            validity, isValid, score, deviceType, device, false)
        ;
  }

  /**
   * @param exerciseID
   * @param exercise1
   * @param questionID
   * @param user
   * @param reqid
   * @param audioType
   * @param doFlashcard
   * @param recordInResults
   * @param recordedWithFlash
   * @param wavPath
   * @param file
   * @param validity
   * @param isValid
   * @param deviceType
   * @param device
   * @param allowAlternates
   * @param useOldSchool
   * @return
   * @see #getAnswer
   * @see #writeAudioFile(String, String, CommonExercise, int, int, int, String, boolean, boolean, boolean, String, String, boolean, boolean)
   */
  private AudioAnswer getAudioAnswerDecoding(String exerciseID, CommonExercise exercise1,
                                             int questionID,
                                             int user,
                                             int reqid,
                                             String audioType, boolean doFlashcard, boolean recordInResults,
                                             boolean recordedWithFlash, String wavPath, File file,
                                             AudioCheck.ValidityAndDur validity, boolean isValid,
                                             String deviceType, String device, boolean allowAlternates, boolean useOldSchool) {
    checkValidity(exerciseID, questionID, user, file, validity, isValid);
    AudioAnswer answer = getAudioAnswer(exercise1, reqid, doFlashcard, wavPath, file, validity, isValid, true, allowAlternates, useOldSchool);

    if (recordInResults) {
      long then = System.currentTimeMillis();
      JSONObject json = new ScoreToJSON().getJsonFromAnswer(answer);
      // logger.debug("json is " + json);
      long now = System.currentTimeMillis();
      if (now - then > 10) {
        logger.debug("took " + (now - then) + " to convert answer to json");
      }
      String scoreJson = json.toString();
      PretestScore pretestScore = answer.getPretestScore();

      int processDur = pretestScore == null ? 0 : pretestScore.getProcessDur();

      if (pretestScore != null) {
        logger.info("getAudioAnswerDecoding got pretest score = " + pretestScore + " and duration = " + processDur);
      } else {
        //logger.warn("no pretest score");
      }

      long answerID = db.addAudioAnswer(user, exerciseID, questionID, file.getPath(),
          isValid, audioType, validity.durationInMillis, answer.isCorrect(), (float) answer.getScore(),
          recordedWithFlash, deviceType, device, scoreJson, processDur,
          validity.getValidity().toString(),
          (float) validity.getMaxMinRange());
      answer.setResultID(answerID);

      db.recordWordAndPhoneInfo(answer, answerID);
    }
    //   logger.debug("getAudioAnswerDecoding answer " + answer);
    return answer;
  }

  /**
   * Does alignment and decoding of one audio file.
   *
   * @param exercise
   * @param attribute
   * @param doHydec
   * @see mitll.langtest.server.decoder.RefResultDecoder#doDecode
   */
  public void decodeOneAttribute(CommonExercise exercise, AudioAttribute attribute, boolean doHydec) {
    if (isInDictOrLTS(exercise)) {
      String audioRef = attribute.getAudioRef();
      if (!audioRef.contains("context=")) {
        //logger.debug("doing alignment -- ");
        // Do alignment...
        File absoluteFile = pathHelper.getAbsoluteFile(audioRef);
        String absolutePath = absoluteFile.getAbsolutePath();

        PretestScore alignmentScore = getAlignmentScore(exercise, absolutePath, serverProps.usePhoneToDisplay(), false);
        DecodeAlignOutput alignOutput = new DecodeAlignOutput(alignmentScore, false);

        // Do decoding, and record alignment info we just got in the database ...
        long durationInMillis = attribute.getDurationInMillis();
        AudioAnswer decodeAnswer = getRefDecodeAnswer(exercise, audioRef, absoluteFile, durationInMillis, false);
        DecodeAlignOutput decodeOutput = new DecodeAlignOutput(decodeAnswer, true);

        PretestScore alignmentScoreOld = doHydec ? getAlignmentScore(exercise, absolutePath,
            serverProps.usePhoneToDisplay(), true) : new PretestScore();
        DecodeAlignOutput alignOutputOld = new DecodeAlignOutput(alignmentScoreOld, false);

        // Do decoding, and record alignment info we just got in the database ...
        AudioAnswer decodeAnswerOld = doHydec ? getRefDecodeAnswer(exercise, audioRef, absoluteFile, durationInMillis, true) : new AudioAnswer();
        DecodeAlignOutput decodeOutputOld = new DecodeAlignOutput(decodeAnswerOld, true);

        //logger.debug("attr dur " + attribute.getDurationInMillis());

        getRefAudioAnswerDecoding(exercise, (int) attribute.getUserid(),
            //audioRef,
            absoluteFile,
            durationInMillis,

            alignOutput,
            decodeOutput,

            alignOutputOld,
            decodeOutputOld,

            attribute.isMale(),
            attribute.isRegularSpeed() ? REG : SLOW);
      }
    } else {
      logger.warn("skipping " + exercise.getID() + " since can't do decode/align b/c of LTS errors ");
    }
  }

  /**
   * Really helpful - could have annotation info always at hand, so don't have to wait for it in learn tab...
   * AND we can send it along to the iPad and have it do highlighting of words and phones in time with the audio
   * I.E. Follow the bouncing ball.
   *
   * @param exercise1
   * @param user
   * @param file
   * @param duration
   * @param isMale
   * @param speed
   * @return
   * @paramx wavPath
   * @paramx numAlignPhones
   * @see #decodeOneAttribute(CommonExercise, AudioAttribute, boolean)
   */
  private void getRefAudioAnswerDecoding(CommonExercise exercise1,
                                         int user,

                                         File file, long duration,
                                         DecodeAlignOutput alignOutput,
                                         DecodeAlignOutput decodeOutput,

                                         DecodeAlignOutput alignOutputOld,
                                         DecodeAlignOutput decodeOutputOld,

                                         boolean isMale, String speed) {
    AudioCheck.ValidityAndDur validity = new AudioCheck.ValidityAndDur(AudioAnswer.Validity.OK, duration);
    // logger.debug("validity dur " + validity.durationInMillis);

    db.addRefAnswer(user, exercise1.getID(), file.getPath(),
        validity.durationInMillis,

        decodeOutput.isCorrect(),

        alignOutput,
        decodeOutput,

        alignOutputOld,
        decodeOutputOld,

        isMale, speed);
    // TODO : add word and phone table for refs
    //	recordWordAndPhoneInfo(decodeAnswer, answerID);
    //   logger.debug("getRefAudioAnswerDecoding decodeAnswer " + decodeAnswer);
  }

  private AudioAnswer getRefDecodeAnswer(CommonExercise exercise1, String wavPath, File file, long duration, boolean useOldSchool) {
    return getAudioAnswer(exercise1, 1, true, wavPath, file, new AudioCheck.ValidityAndDur(AudioAnswer.Validity.OK, duration), true, false, false, useOldSchool);
  }

  private void checkValidity(String exerciseID, int questionID, int user, File file, AudioCheck.ValidityAndDur validity,
                             boolean isValid) {
    if (!isValid) {
      logger.warn("got invalid audio file (" + validity +
          ") user = " + user + " exerciseID " + exerciseID +
          " question " + questionID + " file " + file.getAbsolutePath());
    }
  }

  /**
   * @param exerciseID
   * @param exercise1
   * @param questionID
   * @param user
   * @param reqid
   * @param audioType
   * @param doFlashcard
   * @param recordInResults
   * @param recordedWithFlash
   * @param wavPath
   * @param file
   * @param validity
   * @param isValid
   * @param score
   * @param deviceType
   * @param device
   * @param useOldSchool
   * @return
   * @see #getAnswer(String, CommonExercise, int, boolean, String, File, String, String, float, int, boolean)
   */
  private AudioAnswer getAudioAnswerAlignment(String exerciseID, CommonExercise exercise1,
                                              int questionID,
                                              int user,
                                              int reqid,
                                              String audioType, boolean doFlashcard, boolean recordInResults,
                                              boolean recordedWithFlash, String wavPath, File file,
                                              AudioCheck.ValidityAndDur validity, boolean isValid,
                                              float score, String deviceType, String device, boolean useOldSchool) {
    checkValidity(exerciseID, questionID, user, file, validity, isValid);
    AudioAnswer answer = getAudioAnswer(exercise1, reqid, doFlashcard, wavPath, file, validity, isValid, true, false, useOldSchool);

    if (recordInResults) {
      int processDur = answer.getPretestScore() == null ? 0 : answer.getPretestScore().getProcessDur();
      long answerID = db.addAudioAnswer(user, exerciseID, questionID, file.getPath(),
          isValid, audioType, validity.durationInMillis, true, score, recordedWithFlash, deviceType, device,
          new ScoreToJSON().getJsonFromAnswer(answer).toString(), processDur, validity.getValidity().name(), validity.getMaxMinRange());
      answer.setResultID(answerID);
    }
    logger.debug("getAudioAnswerAlignment answer " + answer);
    return answer;
  }

  /**
   * @param exercise1
   * @param reqid
   * @param doFlashcard
   * @param wavPath
   * @param file
   * @param validity
   * @param isValid
   * @param canUseCache
   * @param allowAlternates
   * @param useOldSchool
   * @return
   * @see #getAudioAnswerDecoding
   */
  private AudioAnswer getAudioAnswer(CommonExercise exercise1, int reqid, boolean doFlashcard, String wavPath, File file,
                                     AudioCheck.ValidityAndDur validity, boolean isValid, boolean canUseCache,
                                     boolean allowAlternates, boolean useOldSchool) {
    String url = pathHelper.ensureForwardSlashes(wavPath);

    return (isValid && !serverProps.isNoModel()) ?
        getAudioAnswer(
            exercise1,
            reqid, file, validity, url, doFlashcard, canUseCache, allowAlternates, useOldSchool) :
        new AudioAnswer(url, validity.getValidity(), reqid, validity.durationInMillis);
  }

  /**
   * @param base64EncodedString
   * @param textToAlign
   * @param identifier
   * @param reqid
   * @return
   * @see mitll.langtest.server.LangTestDatabaseImpl#getAlignment
   */
  public AudioAnswer getAlignment(String base64EncodedString, String textToAlign, String identifier, int reqid, boolean usePhoneToDisplay) {
    File file = getPostedFileLoc();
    AudioAnswer audioAnswer = getAudioAnswer(base64EncodedString, reqid, file);

    if (audioAnswer.isValid()) {
      PretestScore asrScoreForAudio = getASRScoreForAudio(reqid, file.getAbsolutePath(), textToAlign, null, -1, -1, false,
          false, Files.createTempDir().getAbsolutePath(), serverProps.useScoreCache(), identifier, null, usePhoneToDisplay, false);

      audioAnswer.setPretestScore(asrScoreForAudio);
    } else {
      logger.warn("got invalid audio file (" + audioAnswer.getValidity() + ") identifier " + identifier + " file " + file.getAbsolutePath());
    }

    return audioAnswer;
  }

  private File getPostedFileLoc() {
    return getPathUnder(POSTED_AUDIO);
  }

  private File getPathUnder(String postedAudio) {
    String wavPath = pathHelper.getWavPathUnder(postedAudio);
    return pathHelper.getAbsoluteFile(wavPath);
  }

  private AudioAnswer getAudioAnswer(String base64EncodedString, int reqid, File file) {
    AudioCheck.ValidityAndDur validity = new AudioConversion(serverProps).convertBase64ToAudioFiles(base64EncodedString, file, false);
    //logger.debug("writing to " + file.getAbsolutePath() + " answer " + audioAnswer);
    return new AudioAnswer(pathHelper.ensureForwardSlashes(pathHelper.getWavPathUnder(POSTED_AUDIO)),
        validity.getValidity(), reqid, validity.durationInMillis);
  }

  @Override
  public PretestScore getASRScoreForAudio(File testAudioFile, Collection<String> lmSentences, boolean canUseCache, boolean useOldSchool) {
    return getASRScoreForAudio(testAudioFile, lmSentences, canUseCache, serverProps.usePhoneToDisplay(), useOldSchool);
  }

  /**
   * Get score when doing autoCRT on an audio file.
   * <p>
   * TODO : why even generate images here???
   *
   * @param testAudioFile     audio file to score
   * @param lmSentences       to look for in the audio
   * @param canUseCache
   * @param usePhoneToDisplay
   * @param useOldSchool
   * @return PretestScore for audio
   * @see AutoCRT#getFlashcardAnswer
   * @see AutoCRTScoring#getASRScoreForAudio(File, Collection, boolean, boolean)
   */
  private PretestScore getASRScoreForAudio(File testAudioFile, Collection<String> lmSentences, boolean canUseCache,
                                           boolean usePhoneToDisplay, boolean useOldSchool) {
    String tmpDir = Files.createTempDir().getAbsolutePath();
    makeASRScoring();
    List<String> unk = new ArrayList<String>();

    createSLFFile(lmSentences, tmpDir, -1.2f);

    if (isMacOrWin() || useOldSchoolServiceOnly || useOldSchool) {  // i.e. NOT using cool new jcodr webservice
      unk.add(SLFFile.UNKNOWN_MODEL); // if  you don't include this dcodr will say : ERROR: word UNKNOWNMODEL is not in the dictionary!
    }

    String vocab = asrScoring.getUsedTokens(lmSentences, unk); // this is basically the transcript
    String prefix = usePhoneToDisplay ? "phoneToDisplay" : "";
    return getASRScoreForAudio(0, testAudioFile.getPath(), vocab, lmSentences, 128, 128, false, true, tmpDir,
        canUseCache && serverProps.useScoreCache(), prefix, null, usePhoneToDisplay, useOldSchool);
  }

  /**
   * @param lmSentences
   * @param tmpDir
   * @param unknownModelBiasWeight
   * @return
   * @see #getASRScoreForAudio
   */

  private void createSLFFile(Collection<String> lmSentences, String tmpDir, float unknownModelBiasWeight) {
    new SLFFile().createSimpleSLFFile(lmSentences, tmpDir, unknownModelBiasWeight);
  }

  /**
   * @return
   * @see #decodeOneAttribute(CommonExercise, AudioAttribute, boolean)
   */
  public PretestScore getAlignmentScore(CommonExercise exercise, String testAudioPath, boolean usePhoneToDisplay, boolean useOldSchool) {
    return getASRScoreForAudio(0, testAudioPath, exercise.getRefSentence(), 128, 128, false,
        false, Files.createTempDir().getAbsolutePath(), serverProps.useScoreCache(), exercise.getID(), null, usePhoneToDisplay, useOldSchool);
  }

  /**
   * For now, we don't use a ref audio file, since we aren't comparing against a ref audio file with the DTW/sv pathway.
   *
   * @param reqid
   * @param testAudioFile
   * @param sentence           empty string when using lmSentences non empty and vice-versa
   * @param width              image dim
   * @param height             image dim
   * @param useScoreToColorBkg
   * @param decode
   * @param tmpDir
   * @param useCache
   * @param prefix
   * @param precalcResult
   * @param useOldSchool
   * @return PretestScore
   * @seex #getASRScoreForAudio(int, String, String, int, int, boolean)
   * @see mitll.langtest.server.scoring.AutoCRTScoring#getASRScoreForAudio
   * @see mitll.langtest.client.scoring.ScoringAudioPanel#scoreAudio(String, long, String, mitll.langtest.client.scoring.AudioPanel.ImageAndCheck, mitll.langtest.client.scoring.AudioPanel.ImageAndCheck, int, int, int)
   **/

  public PretestScore getASRScoreForAudio(int reqid, String testAudioFile, String sentence,
                                          int width, int height, boolean useScoreToColorBkg,
                                          boolean decode, String tmpDir, boolean useCache, String prefix, Result precalcResult,
                                          boolean usePhoneToDisplay, boolean useOldSchool) {
    return getASRScoreForAudio(reqid, testAudioFile, sentence, null, width, height, useScoreToColorBkg, decode, tmpDir,
        useCache, prefix, precalcResult, usePhoneToDisplay, useOldSchool);
  }

  /**
   * If trying asr webservice and it doesn't work, falls back to using hydec - {@link PretestScore#isRanNormally()}
   * `
   *
   * @param reqid
   * @param testAudioFile
   * @param sentence
   * @param lmSentences
   * @param width
   * @param height
   * @param useScoreToColorBkg
   * @param decode
   * @param tmpDir
   * @param useCache
   * @param prefix
   * @param precalcResult
   * @param useOldSchool
   * @return
   * @see #getASRScoreForAudio(File, Collection, boolean, boolean, boolean)
   */
  private PretestScore getASRScoreForAudio(int reqid, String testAudioFile, String sentence, Collection<String> lmSentences,
                                           int width, int height, boolean useScoreToColorBkg,
                                           boolean decode, String tmpDir, boolean useCache, String prefix, Result precalcResult,
                                           boolean usePhoneToDisplay, boolean useOldSchool) {
/*    try {
      String hostName = InetAddress.getLocalHost().getHostName();
      logger.info("Got host " +hostName);
    } catch (UnknownHostException e) {
      e.printStackTrace();
    }*/

    logger.debug("getASRScoreForAudio (" + serverProps.getLanguage() + ")" + (decode ? " Decoding " : " Aligning ") +
        "" + testAudioFile + " with sentence '" + sentence + "' req# " + reqid + (useCache ? " check cache" : " NO CACHE") + " prefix " + prefix);

    // audio stuff
    makeASRScoring();
    if (testAudioFile == null) {
      logger.error("huh? no test audio file for " + sentence);
      return new PretestScore(); // very defensive
    }
    testAudioFile = mp3Support.dealWithMP3Audio(testAudioFile);
    if (!new File(testAudioFile).exists()) {
      String absolutePath = pathHelper.getAbsolute(pathHelper.getInstallPath(), testAudioFile).getAbsolutePath();
      if (!new File(absolutePath).exists()) {
        logger.error("huh? no testAudioFile for " + sentence + " at " + new File(testAudioFile).getAbsolutePath() + " or " + absolutePath);
        return new PretestScore();
      }
    }

    String installPath = pathHelper.getInstallPath();

    DirAndName testDirAndName = new DirAndName(testAudioFile, installPath).invoke();
    String testAudioName = testDirAndName.getName();
    String testAudioDir  = testDirAndName.getDir();

    if (isEnglishSite()) {
      sentence = sentence.toUpperCase();  // hack for English
    }

    ASR asrScoring = useOldSchool || serverProps.getOldSchoolService() ? oldschoolScoring : getASRScoring();

    logger.info("getASRScoreForAudio : for " + testAudioName + " sentence '" + sentence + "' lm sentences '" + lmSentences + "'");

    PretestScore pretestScore = asrScoring.scoreRepeat(
        testAudioDir, removeSuffix(testAudioName),
        sentence, lmSentences,
        pathHelper.getImageOutDir(), width, height, useScoreToColorBkg, decode, tmpDir, useCache, prefix, precalcResult, usePhoneToDisplay);

    if (!pretestScore.isRanNormally() && isWebservice(asrScoring)) {
      logger.warn("Using hydec as fallback for " + (decode ? " decoding " : " aligning ") + testAudioFile);
      pretestScore = oldschoolScoring.scoreRepeat(
          testAudioDir, removeSuffix(testAudioName),
          sentence, lmSentences,
          pathHelper.getImageOutDir(), width, height, useScoreToColorBkg, decode, tmpDir, useCache, prefix, precalcResult, usePhoneToDisplay);
    }
    pretestScore.setReqid(reqid);

    JSONObject json = new ScoreToJSON().getJsonObject(pretestScore);
    pretestScore.setJson(json.toString());

    return pretestScore;
  }

  private boolean isEnglishSite() {
    return serverProps.getLanguage().equalsIgnoreCase("English");
  }

  /**
   * Just for testing!
   *
   * @param e
   * @param audioFile
   * @param answer
   * @see mitll.langtest.server.test.RecoTest#isMatch
   */
  public PretestScore getFlashcardAnswer(CommonExercise e, File audioFile, AudioAnswer answer) {
    return this.autoCRT.getFlashcardAnswer(e, audioFile, answer, this.serverProps.getLanguage(), true, false, false);
  }

  private String removeSuffix(String audioFile) {
    return audioFile.substring(0, audioFile.length() - ("." + AudioTag.COMPRESSED_TYPE).length());
  }

  public String getWavForMP3(String audioFile) {
    return mp3Support.getWavForMP3(audioFile);
  }

  /**
   * Does decoding if doFlashcard is true.
   * TODO : refactor this so it's
   *
   * @param reqid
   * @param file
   * @param validity
   * @param url
   * @param doFlashcard     true if should do decoding false if should not do anything
   * @param canUseCache
   * @param allowAlternates
   * @param useOldSchool
   * @return AudioAnswer with decode info attached, if doFlashcard is true
   * @see #writeAudioFile
   */
  private AudioAnswer getAudioAnswer(CommonExercise exercise,
                                     int reqid,
                                     File file, AudioCheck.ValidityAndDur validity, String url, boolean doFlashcard,
                                     boolean canUseCache, boolean allowAlternates, boolean useOldSchool) {
    AudioAnswer audioAnswer = new AudioAnswer(url, validity.getValidity(), reqid, validity.durationInMillis);
    if (doFlashcard) {
      makeASRScoring();
      PretestScore flashcardAnswer = autoCRT.getFlashcardAnswer(exercise, file, audioAnswer, serverProps.getLanguage(),
          canUseCache, allowAlternates, useOldSchool);
      audioAnswer.setPretestScore(flashcardAnswer);
      return audioAnswer;
    }
    return audioAnswer;
  }

  public Map<String, Integer> getPhoneToCount() {
    return phoneToCount;
  }

  public static class ScoreAndAnswer {
    public final PretestScore score;
    public final AudioAnswer answer;

    public ScoreAndAnswer(PretestScore score, AudioAnswer answer) {
      this.score = score;
      this.answer = answer;
    }
  }

  /**
   * @return
   * @see #getASRScoreForAudio(int, String, String, Collection, int, int, boolean, boolean, String, boolean, String, Result, boolean, boolean)
   */
  private ASR getASRScoring() {
    return webserviceScoring;
  }

  private boolean isWebservice(ASR asr) {
    return asr == webserviceScoring;
  }

  private boolean isMacOrWin() {
    String property = System.getProperty("os.name").toLowerCase();
    return property.contains("mac") || property.contains("win");
  }

  // TODO: gross
  private void makeASRScoring() {
    if (webserviceScoring == null) {
      webserviceScoring = new ASRWebserviceScoring(pathHelper.getInstallPath(), serverProps, logAndNotify);
      oldschoolScoring = new ASRScoring(pathHelper.getInstallPath(), serverProps, logAndNotify);
    }
    asrScoring = oldschoolScoring;
  }

  /**
   * @see #AudioFileHelper(PathHelper, ServerProperties, DatabaseImpl, LogAndNotify)
   */
  private void makeAutoCRT() {
    autoCRT = new AutoCRT(this, serverProps.getMinPronScore());
  }

  /**
   * @see #getASRScoreForAudio
   */
  private static class DirAndName {
    private final String testAudioFile;
    private final String installPath;
    private String testAudioName;
    private String testAudioDir;

    public DirAndName(String testAudioFile, String installPath) {
      this.testAudioFile = testAudioFile;
      this.installPath = installPath;
    }

    public String getName() {
      return testAudioName;
    }

    public String getDir() {
      return testAudioDir;
    }

    public DirAndName invoke() {
      File testAudio = new File(testAudioFile);
      testAudioName = testAudio.getName();
      if (testAudio.getParent().startsWith(installPath)) {
        testAudioDir = testAudio.getParent().substring(installPath.length());
      } else {
        testAudioDir = testAudio.getParent();
      }

      return this;
    }
  }
}