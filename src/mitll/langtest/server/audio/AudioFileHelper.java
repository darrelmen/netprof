package mitll.langtest.server.audio;

import com.google.common.io.Files;
import mitll.langtest.client.AudioTag;
import mitll.langtest.server.LangTestDatabaseImpl;
import mitll.langtest.server.PathHelper;
import mitll.langtest.server.ServerProperties;
import mitll.langtest.server.autocrt.AutoCRT;
import mitll.langtest.server.database.DatabaseImpl;
import mitll.langtest.server.database.PhoneDAO;
import mitll.langtest.server.database.WordDAO;
import mitll.langtest.server.scoring.*;
import mitll.langtest.shared.AudioAnswer;
import mitll.langtest.shared.AudioAttribute;
import mitll.langtest.shared.CommonExercise;
import mitll.langtest.shared.Result;
import mitll.langtest.shared.instrumentation.TranscriptSegment;
import mitll.langtest.shared.scoring.NetPronImageType;
import mitll.langtest.shared.scoring.PretestScore;
import net.sf.json.JSONArray;
import net.sf.json.JSONObject;
import org.apache.log4j.Logger;

import java.io.File;
import java.math.BigDecimal;
import java.text.Collator;
import java.util.*;

/**
 * Created with IntelliJ IDEA.
 * User: GO22670
 * Date: 8/8/13
 * Time: 5:08 PM
 * To change this template use File | Settings | File Templates.
 */
public class AudioFileHelper implements CollationSort {
  private static final Logger logger = Logger.getLogger(AudioFileHelper.class);
  private static final String POSTED_AUDIO = "postedAudio";

  private final PathHelper pathHelper;
  private final ServerProperties serverProps;
  private ASR asrScoring;
  private ASRScoring oldschoolScoring;
  private ASRWebserviceScoring webserviceScoring;
  private AutoCRT autoCRT;
  private final DatabaseImpl db;
  private final LangTestDatabaseImpl langTestDatabase;
  private boolean checkedLTS = false;
  private Map<String, Integer> phoneToCount;
  private boolean useOldSchoolServiceOnly = false;

  /**
   * @param pathHelper
   * @param serverProperties
   * @param db
   * @param langTestDatabase
   * @see mitll.langtest.server.ScoreServlet#getAudioFileHelper()
   */
  public AudioFileHelper(PathHelper pathHelper, ServerProperties serverProperties, DatabaseImpl db,
                         LangTestDatabaseImpl langTestDatabase) {
    this.pathHelper = pathHelper;
    this.serverProps = serverProperties;
    this.db = db;
    this.langTestDatabase = langTestDatabase;
    this.useOldSchoolServiceOnly = serverProperties.getOldSchoolService();
  }

  public <T extends CommonExercise> void sort(List<T> toSort) {
    asrScoring.sort(toSort);
  }

  /**
   * @return
   * @see mitll.langtest.server.scoring.ASRScoring#getCollator
   */
  @Override
  public Collator getCollator() {
    makeASRScoring();
    return asrScoring.getCollator();
  }

  /**
   * @param exercises
   */
  public void checkLTS(List<CommonExercise> exercises) {
    synchronized (this) {
      if (!checkedLTS) {
        checkedLTS = true;
        int count = 0;
        makeASRScoring();

        phoneToCount = new HashMap<String, Integer>();
        for (CommonExercise exercise : exercises) {
          boolean validForeignPhrase = asrScoring.checkLTS(exercise.getForeignLanguage());
          if (!validForeignPhrase) {
            if (count < 10) {
              logger.error("huh? for " + exercise.getID() + " we can't parse " + exercise.getID() + " " + exercise.getEnglish() + " fl " + exercise.getForeignLanguage());
            }
            count++;
          } else {
            countPhones(exercise);
          }
        }

        if (count > 0) {
          logger.error("huh? out of " + exercises.size() + " LTS fails on " + count);
        }
      }
    }
  }

  private void countPhones(CommonExercise exercise) {
    ASR.PhoneInfo bagOfPhones = asrScoring.getBagOfPhones(exercise.getForeignLanguage());
    exercise.setBagOfPhones(bagOfPhones.getPhoneSet());
    exercise.setFirstPron(bagOfPhones.getFirstPron());

    for (String phone : bagOfPhones.getFirstPron()) {
      Integer integer = getPhoneToCount().get(phone);
      getPhoneToCount().put(phone, integer == null ? 1 : integer + 1);
    }
  }

  /**
   * @param foreignLanguagePhrase
   * @return
   * @see mitll.langtest.server.LangTestDatabaseImpl#isValidForeignPhrase(String)
   */
  public boolean checkLTS(String foreignLanguagePhrase) {
    makeASRScoring();
    return asrScoring.checkLTS(foreignLanguagePhrase);
  }

  public SmallVocabDecoder getSmallVocabDecoder() {
    makeASRScoring();
    return asrScoring.getSmallVocabDecoder();
  }

  /**
   * Record an answer entry in the database.<br></br>
   * Write the posted data to a wav and an mp3 file (since all the browser audio works with mp3).
   * <p/>
   * Client references:
   *
   * @param base64EncodedString generated by flash on the client
   * @param exerciseID
   * @param exercise1           exerciseID within the plan
   * @param questionID          question within the exerciseID
   * @param user                answering the question
   * @param reqid               request id from the client, so it can potentially throw away out of order responses
   * @param audioType           regular or fast then slow audio recording
   * @param doFlashcard         true if decoding
   * @param recordInResults     true if we should add info to the results table
   * @param recordedWithFlash   true if recorded with Flash, false if via webRTC
   * @param deviceType          browser or iPad or iPhone
   * @param device              browser make and version or iPad unique id
   * @param isRefRecording
   * @param allowAlternates
   * @return URL to audio on server and if audio is valid (not too short, etc.)
   * @see mitll.langtest.client.scoring.PostAudioRecordButton#stopRecording()
   * @see mitll.langtest.client.recorder.RecordButtonPanel#stopRecording()
   * @see LangTestDatabaseImpl#writeAudioFile
   */
  public AudioAnswer writeAudioFile(String base64EncodedString, String exerciseID, CommonExercise exercise1, int questionID,
                                    int user, int reqid, String audioType, boolean doFlashcard,
                                    boolean recordInResults, boolean recordedWithFlash, String deviceType, String device,
                                    boolean isRefRecording, boolean allowAlternates) {
    String wavPath = pathHelper.getLocalPathToAnswer("plan", exerciseID, questionID, user);
    File file = pathHelper.getAbsoluteFile(wavPath);

    long then = System.currentTimeMillis();
    AudioCheck.ValidityAndDur validity = new AudioConversion().convertBase64ToAudioFiles(base64EncodedString, file, isRefRecording);
    long now = System.currentTimeMillis();
    long diff = now - then;
    if (diff > 20) {
      logger.debug("took " + diff + " millis to write wav file " + validity.durationInMillis + " millis long");
    }
    boolean isValid = validity.validity == AudioAnswer.Validity.OK || (serverProps.isQuietAudioOK() && validity.validity == AudioAnswer.Validity.TOO_QUIET);
    return getAudioAnswerDecoding(exerciseID, exercise1, questionID, user, reqid, audioType, doFlashcard, recordInResults,
        recordedWithFlash, wavPath, file, validity, isValid
        , deviceType, device,
        allowAlternates);
  }

  /**
   * TODO : this is misleading - if doFlashcard is true, it does decoding, otherwise it does *not* do alignment
   *
   * @param exerciseID
   * @param exercise1
   * @param user
   * @param doFlashcard
   * @param wavPath
   * @param file
   * @param deviceType
   * @param device
   * @param score
   * @param reqid
   * @param allowAlternates
   * @return
   * @see mitll.langtest.server.ScoreServlet#getAnswer
   */
  public AudioAnswer getAnswer(String exerciseID, CommonExercise exercise1, int user, boolean doFlashcard, String wavPath,
                               File file, String deviceType, String device, float score, int reqid, boolean allowAlternates) {
    String audioType = doFlashcard ? "flashcard" : "learn";
    AudioCheck.ValidityAndDur validity = new AudioConversion().isValid(file, false);
    boolean isValid =
        validity.validity == AudioAnswer.Validity.OK ||
            (serverProps.isQuietAudioOK() && validity.validity == AudioAnswer.Validity.TOO_QUIET);

    return doFlashcard ?
        getAudioAnswerDecoding (exerciseID, exercise1, 0, user, reqid, audioType, doFlashcard, true, true, wavPath, file,
            validity, isValid, deviceType, device, allowAlternates) :
        getAudioAnswerAlignment(exerciseID, exercise1, 0, user, reqid, audioType, doFlashcard, true, true, wavPath, file,
            validity, isValid, score, deviceType, device)
        ;
  }

  /**
   * @param exerciseID
   * @param exercise1
   * @param questionID
   * @param user
   * @param reqid
   * @param audioType
   * @param doFlashcard
   * @param recordInResults
   * @param recordedWithFlash
   * @param wavPath
   * @param file
   * @param validity
   * @param isValid
   * @param deviceType
   * @param device
   * @param allowAlternates
   * @return
   * @see #getAnswer
   * @see #writeAudioFile(String, String, CommonExercise, int, int, int, String, boolean, boolean, boolean, String, String, boolean, boolean)
   */
  private AudioAnswer getAudioAnswerDecoding(String exerciseID, CommonExercise exercise1,
                                             int questionID,
                                             int user,
                                             int reqid,
                                             String audioType, boolean doFlashcard, boolean recordInResults,
                                             boolean recordedWithFlash, String wavPath, File file,
                                             AudioCheck.ValidityAndDur validity, boolean isValid,
                                             String deviceType, String device, boolean allowAlternates) {
    checkValidity(exerciseID, questionID, user, file, validity, isValid);
    AudioAnswer answer = getAudioAnswer(exercise1, reqid, doFlashcard, wavPath, file, validity, isValid, true, allowAlternates);

    if (recordInResults) {
      long then = System.currentTimeMillis();
      JSONObject json = getJson(answer);
     // logger.debug("json is " + json);
      long now = System.currentTimeMillis();
      if (now - then > 10) {
        logger.debug("took " + (now - then) + " to convert answer to json");
      }
      String scoreJson = json.toString();
      PretestScore pretestScore = answer.getPretestScore();

      int processDur = pretestScore == null ? 0 : pretestScore.getProcessDur();

      if (pretestScore != null) {
          logger.info("getAudioAnswerDecoding got pretest score = " + pretestScore + " and duration = " + processDur);
      }

      long answerID = db.addAudioAnswer(user, exerciseID, questionID, file.getPath(),
          isValid, audioType, validity.durationInMillis, answer.isCorrect(), (float) answer.getScore(),
          recordedWithFlash, deviceType, device, scoreJson, processDur);
      answer.setResultID(answerID);

      recordWordAndPhoneInfo(answer, answerID);
    }
 //   logger.debug("getAudioAnswerDecoding answer " + answer);
    return answer;
  }

  /**
   * Does alignment and decoding of one audio file.
   *
   * @param exercise
   * @param attribute
   * @see LangTestDatabaseImpl#doDecode(Set, CommonExercise, Collection)
   */
  public void decodeOneAttribute(CommonExercise exercise, AudioAttribute attribute) {
    if (asrScoring.checkLTS(exercise.getForeignLanguage())) {
      String audioRef = attribute.getAudioRef();
      if (!audioRef.contains("context=")) {
        //logger.debug("doing alignment -- ");

        // Do alignment...
        long then = System.currentTimeMillis();
        PretestScore alignmentScore = getAlignmentScore(exercise, pathHelper.getAbsoluteFile(audioRef).getAbsolutePath(),serverProps.usePhoneToDisplay());
        long now = System.currentTimeMillis();
        logger.debug("Took " + (now - then) + " to do alignment");

        //logger.debug("doing decoding -- ");
        then = System.currentTimeMillis();

        // Do decoding, and record alignment info we just got in the database ...

        getRefAudioAnswerDecoding(exercise, (int) attribute.getUserid(), audioRef, pathHelper.getAbsoluteFile(audioRef),
            attribute.getDurationInMillis(),

            alignmentScore.getHydecScore(), getJsonObject(alignmentScore).toString(), numPhones(alignmentScore),

            attribute.isMale(),
            attribute.isRegularSpeed() ? "reg" : "slow");

        now = System.currentTimeMillis();
        logger.debug("Took " + (now - then) + " to do decoding");
      }
    } else {
      logger.warn("skipping " + exercise.getID() + " since can't do decode/align b/c of LTS errors ");
    }
  }

  /**
   * Really helpful - could have annotation info always at hand, so don't have to wait for it in learn tab...
   * AND we can send it along to the iPad and have it do highlighting of words and phones in time with the audio
   * I.E. Follow the bouncing ball.
   *
   * @param exercise1
   * @param user
   * @param wavPath
   * @param file
   * @param duration
   * @param numAlignPhones
   * @param isMale
   * @param speed
   * @return
   * @see #decodeOneAttribute(CommonExercise, AudioAttribute)
   */
  private void getRefAudioAnswerDecoding(CommonExercise exercise1,
                                         int user, String wavPath, File file, long duration,
                                         float alignScore, String alignJson,
                                         int numAlignPhones,
                                         boolean isMale, String speed) {
    AudioCheck.ValidityAndDur validity = new AudioCheck.ValidityAndDur(AudioAnswer.Validity.OK, duration);
    AudioAnswer decodeAnswer = getAudioAnswer(exercise1, 1, true, wavPath, file, validity, true, false, false);

    long then = System.currentTimeMillis();
    JSONObject decodeJSON = getJson(decodeAnswer);
    long now = System.currentTimeMillis();
    if (now - then > 10) {
      logger.debug("took " + (now - then) + " to convert decode answer to JSON");
    }

    db.addRefAnswer(user, exercise1.getID(), file.getPath(),
        validity.durationInMillis, decodeAnswer.isCorrect(),
        (float) decodeAnswer.getScore(), decodeJSON.toString(),
        alignScore, alignJson,
        numPhones(decodeAnswer.getPretestScore()),
        numAlignPhones, isMale, speed);

    // TODO : add word and phone table for refs
    //	recordWordAndPhoneInfo(decodeAnswer, answerID);
    logger.debug("getRefAudioAnswerDecoding decodeAnswer " + decodeAnswer);
  }

  private void checkValidity(String exerciseID, int questionID, int user, File file, AudioCheck.ValidityAndDur validity,
                             boolean isValid) {
    if (!isValid) {
      logger.warn("got invalid audio file (" + validity +
          ") user = " + user + " exerciseID " + exerciseID +
          " question " + questionID + " file " + file.getAbsolutePath());
    }
  }

  /**
   * @param exerciseID
   * @param exercise1
   * @param questionID
   * @param user
   * @param reqid
   * @param audioType
   * @param doFlashcard
   * @param recordInResults
   * @param recordedWithFlash
   * @param wavPath
   * @param file
   * @param validity
   * @param isValid
   * @param score
   * @param deviceType
   * @param device
   * @return
   * @see #getAnswer(String, CommonExercise, int, boolean, String, File, String, String, float, int, boolean)
   */
  private AudioAnswer getAudioAnswerAlignment(String exerciseID, CommonExercise exercise1,
                                              int questionID,
                                              int user,
                                              int reqid,
                                              String audioType, boolean doFlashcard, boolean recordInResults,
                                              boolean recordedWithFlash, String wavPath, File file,
                                              AudioCheck.ValidityAndDur validity, boolean isValid,
                                              float score, String deviceType, String device) {
    checkValidity(exerciseID, questionID, user, file, validity, isValid);
    AudioAnswer answer = getAudioAnswer(exercise1, reqid, doFlashcard, wavPath, file, validity, isValid, true, false);

    if (recordInResults) {
      int processDur = answer.getPretestScore() == null ? 0 : answer.getPretestScore().getProcessDur();
      long answerID = db.addAudioAnswer(user, exerciseID, questionID, file.getPath(),
          isValid, audioType, validity.durationInMillis, true, score, recordedWithFlash, deviceType, device,
          getJson(answer).toString(), processDur);
      answer.setResultID(answerID);
    }
    logger.debug("getAudioAnswerAlignment answer " + answer);
    return answer;
  }

  /**
   * @param exercise1
   * @param reqid
   * @param doFlashcard
   * @param wavPath
   * @param file
   * @param validity
   * @param isValid
   * @param canUseCache
   * @param allowAlternates
   * @return
   * @see #getAudioAnswerDecoding
   */
  private AudioAnswer getAudioAnswer(CommonExercise exercise1, int reqid, boolean doFlashcard, String wavPath, File file,
                                     AudioCheck.ValidityAndDur validity, boolean isValid, boolean canUseCache, boolean allowAlternates) {
    String url = pathHelper.ensureForwardSlashes(wavPath);

    return (isValid && !serverProps.isNoModel()) ?
        getAudioAnswer(
            exercise1,
            reqid, file, validity, url, doFlashcard, canUseCache, allowAlternates) :
        new AudioAnswer(url, validity.validity, reqid, validity.durationInMillis);
  }

  /**
   * Put word and phone scores into database.
   *
   * @param answer
   * @param answerID
   * @see #getAudioAnswerDecoding
   */
  private void recordWordAndPhoneInfo(AudioAnswer answer, long answerID) {
    PretestScore pretestScore = answer.getPretestScore();
    List<TranscriptSegment> words = pretestScore == null ? null : pretestScore.getsTypeToEndTimes().get(NetPronImageType.WORD_TRANSCRIPT);
    List<TranscriptSegment> phones = pretestScore == null ? null : pretestScore.getsTypeToEndTimes().get(NetPronImageType.PHONE_TRANSCRIPT);
    if (words != null) {
      int windex = 0;
      int pindex = 0;

      for (TranscriptSegment segment : words) {
        String event = segment.getEvent();
        if (!event.equals(SLFFile.UNKNOWN_MODEL) && !event.equals("sil")) {
          long wid = db.getWordDAO().addWord(new WordDAO.Word(answerID, event, windex++, segment.getScore()));
          for (TranscriptSegment pseg : phones) {
            if (pseg.getStart() >= segment.getStart() && pseg.getEnd() <= segment.getEnd()) {
              String pevent = pseg.getEvent();
              if (!pevent.equals(SLFFile.UNKNOWN_MODEL) && !pevent.equals("sil")) {
                db.getPhoneDAO().addPhone(new PhoneDAO.Phone(answerID, wid, pevent, pindex++, pseg.getScore()));
              }
            }
          }
        }
      }
    }
  }

  /**
   * We skip sils, since we wouldn't want to show them to the user.
   *
   * @param answer
   * @return
   * @see #getAudioAnswerDecoding
   */
  private JSONObject getJson(AudioAnswer answer) {
    PretestScore pretestScore = answer.getPretestScore();
    return getJsonObject(pretestScore);
  }

  private JSONObject getJsonObject(PretestScore pretestScore) {
    JSONObject jsonObject = new JSONObject();
    if (pretestScore != null) {
      Map<NetPronImageType, List<TranscriptSegment>> netPronImageTypeListMap = pretestScore.getsTypeToEndTimes();
      List<TranscriptSegment> words  = netPronImageTypeListMap.get(NetPronImageType.WORD_TRANSCRIPT);
      List<TranscriptSegment> phones = netPronImageTypeListMap.get(NetPronImageType.PHONE_TRANSCRIPT);
      if (words != null) {
        int windex = 0;
        int pindex = 0;
        JSONArray jsonWords = new JSONArray();

        for (TranscriptSegment segment : words) {
          String event = segment.getEvent();
          if (!event.equals(SLFFile.UNKNOWN_MODEL) && !event.equals("sil")) {
            JSONObject wordJson = new JSONObject();
            String wid = Integer.toString(windex++);
            wordJson.put("id", wid);
            wordJson.put("w", event);
            wordJson.put("s", getScore(segment));
            wordJson.put("str", floatToString(segment.getStart()));
            wordJson.put("end", floatToString(segment.getEnd()));

            JSONArray jsonPhones = new JSONArray();

            for (TranscriptSegment pseg : phones) {
              if (pseg.getStart() >= segment.getStart() && pseg.getEnd() <= segment.getEnd()) {
                String pevent = pseg.getEvent();
                if (!pevent.equals(SLFFile.UNKNOWN_MODEL) && !pevent.equals("sil")) {
                  JSONObject phoneJson = new JSONObject();
                  phoneJson.put("id", Integer.toString(pindex++));
                  phoneJson.put("p", pevent);
                  phoneJson.put("s", getScore(pseg));
                  phoneJson.put("str", floatToString(pseg.getStart()));
                  phoneJson.put("end", floatToString(pseg.getEnd()));
                  jsonPhones.add(phoneJson);
                }
              }
            }
            wordJson.put("phones", jsonPhones);
            jsonWords.add(wordJson);
          }
        }

        jsonObject.put("words", jsonWords);
      }
    }
    return jsonObject;
  }

  private String getScore(TranscriptSegment segment) {
    float score = segment.getScore();
    return floatToString(score);
  }

  private String floatToString(float round) {
    return Float.toString(round(round));
  }

  private int numPhones(PretestScore pretestScore) {
    int c = 0;
    if (pretestScore != null) {
      Map<NetPronImageType, List<TranscriptSegment>> netPronImageTypeListMap = pretestScore.getsTypeToEndTimes();
      List<TranscriptSegment> phones = netPronImageTypeListMap.get(NetPronImageType.PHONE_TRANSCRIPT);

      if (phones != null) {
        for (TranscriptSegment pseg : phones) {
          String pevent = pseg.getEvent();
          if (!pevent.equals(SLFFile.UNKNOWN_MODEL) && !pevent.equals("sil")) {
            c++;
          }
        }
      }
    }
    return c;
  }

  private static float round(float d) {
    return round(d, 3);
  }

  private static float round(float d, int decimalPlace) {
    BigDecimal bd = new BigDecimal(Float.toString(d));
    bd = bd.setScale(decimalPlace, BigDecimal.ROUND_HALF_UP);
    return bd.floatValue();
  }

  /**
   * @param base64EncodedString
   * @param textToAlign
   * @param identifier
   * @param reqid
   * @return
   * @see mitll.langtest.server.LangTestDatabaseImpl#getAlignment
   */
  public AudioAnswer getAlignment(String base64EncodedString, String textToAlign, String identifier, int reqid, boolean usePhoneToDisplay) {
    File file = getPostedFileLoc();
    AudioAnswer audioAnswer = getAudioAnswer(base64EncodedString, reqid, file);

    if (audioAnswer.isValid()) {
      PretestScore asrScoreForAudio = getASRScoreForAudio(reqid, file.getAbsolutePath(), textToAlign, null, -1, -1, false,
          false, Files.createTempDir().getAbsolutePath(), serverProps.useScoreCache(), identifier, null, usePhoneToDisplay);

      audioAnswer.setPretestScore(asrScoreForAudio);
    } else {
      logger.warn("got invalid audio file (" + audioAnswer.getValidity() + ") identifier " + identifier + " file " + file.getAbsolutePath());
    }

    return audioAnswer;
  }

  private File getPostedFileLoc() {
    return getPathUnder(POSTED_AUDIO);
  }

  private File getPathUnder(String postedAudio) {
    String wavPath = pathHelper.getWavPathUnder(postedAudio);
    return pathHelper.getAbsoluteFile(wavPath);
  }

  private AudioAnswer getAudioAnswer(String base64EncodedString, int reqid, File file) {
    AudioCheck.ValidityAndDur validity = new AudioConversion().convertBase64ToAudioFiles(base64EncodedString, file, false);
    //logger.debug("writing to " + file.getAbsolutePath() + " answer " + audioAnswer);
    return new AudioAnswer(pathHelper.ensureForwardSlashes(pathHelper.getWavPathUnder(POSTED_AUDIO)),
        validity.validity, reqid, validity.durationInMillis);
  }

  /**
   * Get score when doing autoCRT on an audio file.
   * <p/>
   * TODO : why even generate images here???
   *
   * @param testAudioFile audio file to score
   * @param lmSentences   to look for in the audio
   * @param canUseCache
   * @param usePhoneToDisplay
   * @return PretestScore for audio
   * @see AutoCRT#getFlashcardAnswer
   * @see AutoCRTScoring#getASRScoreForAudio(File, Collection, boolean)
   */
  public PretestScore getASRScoreForAudio(File testAudioFile, Collection<String> lmSentences, boolean canUseCache, boolean usePhoneToDisplay) {
    String tmpDir = Files.createTempDir().getAbsolutePath();
    makeASRScoring();
    List<String> unk = new ArrayList<String>();

    if (isMacOrWin() || useOldSchoolServiceOnly) {  // i.e. NOT using cool new jcodr webservice
      createSLFFile(lmSentences, tmpDir, -1.2f);
      unk.add(SLFFile.UNKNOWN_MODEL); // if  you don't include this dcodr will say : ERROR: word UNKNOWNMODEL is not in the dictionary!
    }

    String vocab = asrScoring.getUsedTokens(lmSentences, unk); // this is basically the transcript
    //logger.debug("getASRScoreForAudio : vocab " + vocab + " from " + lmSentences);
//    if (isMacOrWin() || useOldSchoolServiceOnly) // we have lm sentences in the webservice version because we make the language model later on
//      return getASRScoreForAudio(0, testAudioFile.getPath(), vocab, lmSentences, 128, 128, false, true, tmpDir,
//          canUseCache && serverProps.useScoreCache(), "", null,usePhoneToDisplay);
//    else

    String prefix = usePhoneToDisplay ? "phoneToDisplay" : "";
      return getASRScoreForAudio(0, testAudioFile.getPath(), vocab, lmSentences, 128, 128, false, true, tmpDir,
          canUseCache && serverProps.useScoreCache(), prefix, null,usePhoneToDisplay);
  }

  /**
   * @param lmSentences
   * @param tmpDir
   * @param unknownModelBiasWeight
   * @return
   * @see #getASRScoreForAudio
   */

  private void createSLFFile(Collection<String> lmSentences, String tmpDir, float unknownModelBiasWeight) {
    new SLFFile().createSimpleSLFFile(lmSentences, tmpDir, unknownModelBiasWeight);
  }

  /**
   * @return
   * @see #decodeOneAttribute(CommonExercise, AudioAttribute)
   */
  private PretestScore getAlignmentScore(CommonExercise exercise, String testAudioPath,boolean usePhoneToDisplay) {
    return getASRScoreForAudio(0, testAudioPath, exercise.getRefSentence(), 128, 128, false,
        false, Files.createTempDir().getAbsolutePath(), serverProps.useScoreCache(), exercise.getID(), null,usePhoneToDisplay);
  }

  /**
   * For now, we don't use a ref audio file, since we aren't comparing against a ref audio file with the DTW/sv pathway.
   *
   * @param reqid
   * @param testAudioFile
   * @param sentence           empty string when using lmSentences non empty and vice-versa
   * @param width              image dim
   * @param height             image dim
   * @param useScoreToColorBkg
   * @param decode
   * @param tmpDir
   * @param useCache
   * @param prefix
   * @param precalcResult
   * @return PretestScore
   * @seex #getASRScoreForAudio(int, String, String, int, int, boolean)
   * @see mitll.langtest.server.scoring.AutoCRTScoring#getASRScoreForAudio
   * @see mitll.langtest.client.scoring.ScoringAudioPanel#scoreAudio(String, long, String, mitll.langtest.client.scoring.AudioPanel.ImageAndCheck, mitll.langtest.client.scoring.AudioPanel.ImageAndCheck, int, int, int)
   **/

  public PretestScore getASRScoreForAudio(int reqid, String testAudioFile, String sentence,
                                          int width, int height, boolean useScoreToColorBkg,
                                          boolean decode, String tmpDir, boolean useCache, String prefix, Result precalcResult,
                                          boolean usePhoneToDisplay) {
    return getASRScoreForAudio(reqid, testAudioFile, sentence, null, width, height, useScoreToColorBkg, decode, tmpDir, useCache, prefix, precalcResult,usePhoneToDisplay);
  }

  /**
   * If trying asr webservice and it doesn't work, falls back to using hydec - {@link PretestScore#isRanNormally()}
   *`
   * @param reqid
   * @param testAudioFile
   * @param sentence
   * @param lmSentences
   * @param width
   * @param height
   * @param useScoreToColorBkg
   * @param decode
   * @param tmpDir
   * @param useCache
   * @param prefix
   * @param precalcResult
   * @return
   * @see #getASRScoreForAudio(File, Collection, boolean, boolean)
   */
  private PretestScore getASRScoreForAudio(int reqid, String testAudioFile, String sentence, Collection<String> lmSentences,
                                           int width, int height, boolean useScoreToColorBkg,
                                           boolean decode, String tmpDir, boolean useCache, String prefix, Result precalcResult,
                                           boolean usePhoneToDisplay) {
    logger.debug("getASRScoreForAudio (" + serverProps.getLanguage() + ")" +
        " scoring " + testAudioFile + " with sentence '" + sentence + "' req# " + reqid + (useCache ? " check cache" : " NO CACHE") + " prefix " + prefix);

    // audio stuff
    makeASRScoring();
    if (testAudioFile == null) {
      logger.error("huh? no test audio file for " + sentence);
      return new PretestScore(); // very defensive
    }
    testAudioFile = dealWithMP3Audio(testAudioFile);
    if (!new File(testAudioFile).exists()) {
      String absolutePath = pathHelper.getAbsolute(pathHelper.getInstallPath(), testAudioFile).getAbsolutePath();
      if (!new File(absolutePath).exists()) {
        logger.error("huh? no testAudioFile for " + sentence + " at " + new File(testAudioFile).getAbsolutePath() + " or " + absolutePath);
        return new PretestScore();
      }
    }

    String installPath = pathHelper.getInstallPath();

    DirAndName testDirAndName = new DirAndName(testAudioFile, installPath).invoke();
    String testAudioName = testDirAndName.getName();
    String testAudioDir  = testDirAndName.getDir();

    if (isEnglishSite()) {
      sentence = sentence.toUpperCase();  // hack for English
    }

    ASR asrScoring = getASRScoring();
    //logger.info("using " +asrScoring);

    logger.info("for " + testAudioName + " sentence " + sentence + " lm sentences " + lmSentences);

    PretestScore pretestScore = asrScoring.scoreRepeat(
        testAudioDir, removeSuffix(testAudioName),
        sentence, lmSentences,
        pathHelper.getImageOutDir(), width, height, useScoreToColorBkg, decode, tmpDir, useCache, prefix, precalcResult, usePhoneToDisplay);

    if (!pretestScore.isRanNormally() && isWebservice(asrScoring)) {
      logger.warn("Using hydec as fallback for " + (decode ? " decoding " : " aligning ") + testAudioFile);
      pretestScore = oldschoolScoring.scoreRepeat(
          testAudioDir, removeSuffix(testAudioName),
          sentence, lmSentences,
          pathHelper.getImageOutDir(), width, height, useScoreToColorBkg, decode, tmpDir, useCache, prefix, precalcResult, usePhoneToDisplay);
    }
    pretestScore.setReqid(reqid);

    JSONObject json = getJsonObject(pretestScore);
    pretestScore.setJson(json.toString());

    return pretestScore;
  }

  private boolean isEnglishSite() {
    return serverProps.getLanguage().equalsIgnoreCase("English");
  }

  /**
   * Just for testing!
   *
   * @param e
   * @param audioFile
   * @param answer
   * @see mitll.langtest.server.RecoTest#isMatch
   */
  public PretestScore getFlashcardAnswer(CommonExercise e, File audioFile, AudioAnswer answer) {
    return this.autoCRT.getFlashcardAnswer(e, audioFile, answer, this.serverProps.getLanguage(), true, false);
  }

  private String removeSuffix(String audioFile) {
    return audioFile.substring(0, audioFile.length() - ("." + AudioTag.COMPRESSED_TYPE).length());
  }

  /**
   * @param testAudioFile
   * @return
   * @see #getASRScoreForAudio(int, String, String, int, int, boolean, boolean, String, boolean, String, Result)
   */
  private String dealWithMP3Audio(String testAudioFile) {
    if (testAudioFile.endsWith("." + AudioTag.COMPRESSED_TYPE)) {
      String noSuffix = removeSuffix(testAudioFile);
      String wavFile = noSuffix + ".wav";
      File test = pathHelper.getAbsoluteFile(wavFile);
      if (!test.exists()) {
        logger.warn("expecting audio file with wav extension, but didn't find " + test.getAbsolutePath());
      }
      return test.exists() ? test.getAbsolutePath() : getWavForMP3(testAudioFile);
    } else {
      return testAudioFile;
    }
  }

  /**
   * @param audioFile
   * @return
   * @see #dealWithMP3Audio(String)
   * @see mitll.langtest.server.LangTestDatabaseImpl#getImageForAudioFile
   */
  public String getWavForMP3(String audioFile) {
    return getWavForMP3(audioFile, pathHelper.getInstallPath());
  }

  /**
   * Ultimately does lame --decode from.mp3 to.wav
   * <p/>
   * Worries about converting from either a relative path to an absolute path (given the webapp install location)
   * or if audioFile is a URL, converting it to a relative path before making an absolute path.
   * <p/>
   * Gotta be a better way...
   *
   * @param audioFile to convert
   * @return
   * @see #getWavForMP3(String)
   */
  private String getWavForMP3(String audioFile, String installPath) {
    assert (audioFile.endsWith(".mp3"));
    String absolutePath = pathHelper.getAbsolute(installPath, audioFile).getAbsolutePath();

    if (!new File(absolutePath).exists())
      logger.error("getWavForMP3 : expecting file at " + absolutePath);
    else {
      AudioConversion audioConversion = new AudioConversion();
      File file = audioConversion.convertMP3ToWav(absolutePath);
      if (file.exists()) {
        String orig = audioFile;
        audioFile = file.getAbsolutePath();
        logger.info("\n\ngetWavForMP3 : from " + orig + " wrote to " + file + " or " + audioFile);
      } else {
        logger.error("getImageForAudioFile : can't find " + file.getAbsolutePath());
      }
    }
    assert (audioFile.endsWith(".wav"));
    return audioFile;
  }

  /**
   * Does decoding if doFlashcard is true.
   * TODO : refactor this so it's
   *
   * @param reqid
   * @param file
   * @param validity
   * @param url
   * @param doFlashcard true if should do decoding false if should not do anything
   * @param canUseCache
   * @param allowAlternates
   * @return AudioAnswer with decode info attached, if doFlashcard is true
   * @see #writeAudioFile
   */
  private AudioAnswer getAudioAnswer(CommonExercise exercise,
                                     int reqid,
                                     File file, AudioCheck.ValidityAndDur validity, String url, boolean doFlashcard,
                                     boolean canUseCache, boolean allowAlternates) {
    AudioAnswer audioAnswer = new AudioAnswer(url, validity.validity, reqid, validity.durationInMillis);
    if (doFlashcard) {
      makeASRScoring();
      PretestScore flashcardAnswer = autoCRT.getFlashcardAnswer(exercise, file, audioAnswer, serverProps.getLanguage(), canUseCache, allowAlternates);
      audioAnswer.setPretestScore(flashcardAnswer);
      return audioAnswer;
    }
    return audioAnswer;
  }

  public Map<String, Integer> getPhoneToCount() {
    return phoneToCount;
  }

  public static class ScoreAndAnswer {
    public final PretestScore score;
    public final AudioAnswer answer;

    public ScoreAndAnswer(PretestScore score, AudioAnswer answer) {
      this.score = score;
      this.answer = answer;
    }
  }

  private ASR getASRScoring() {
    boolean isMacOrWin = false;//isMacOrWin();
    if (!isMacOrWin && !useOldSchoolServiceOnly)
      return webserviceScoring;
    else
      return oldschoolScoring;
  }

  private boolean isWebservice(ASR asr) { return asr == webserviceScoring; }
  private boolean isMacOrWin() {
    String property = System.getProperty("os.name").toLowerCase();
    return property.contains("mac") || property.contains("win");
  }

  // TODO: gross
  private void makeASRScoring() {
    if (webserviceScoring == null) {
      webserviceScoring = new ASRWebserviceScoring(pathHelper.getInstallPath(), serverProps);
      oldschoolScoring  = new ASRScoring(pathHelper.getInstallPath(), serverProps, langTestDatabase);
    }
    asrScoring = oldschoolScoring;
  }

  /**
   * @param crtScoring
   * @paramx studentAnswersDB
   * @paramx langTestDatabase
   * @see mitll.langtest.server.LangTestDatabaseImpl#makeAutoCRT()
   */
  public void makeAutoCRT(AutoCRTScoring crtScoring) {
    if (autoCRT == null) {
      autoCRT = new AutoCRT(crtScoring, serverProps.getMinPronScore());
      //logger.debug("making auto crt " + autoCRT);
    }
  }

  /**
   * @see #getASRScoreForAudio(int, String, String, int, int, boolean, boolean, String, boolean, String, Result)
   */
  private static class DirAndName {
    private final String testAudioFile;
    private final String installPath;
    private String testAudioName;
    private String testAudioDir;

    public DirAndName(String testAudioFile, String installPath) {
      this.testAudioFile = testAudioFile;
      this.installPath = installPath;
    }

    public String getName() {
      return testAudioName;
    }

    public String getDir() {
      return testAudioDir;
    }

    public DirAndName invoke() {
      File testAudio = new File(testAudioFile);
      testAudioName = testAudio.getName();
      if (testAudio.getParent().startsWith(installPath)) {
        testAudioDir = testAudio.getParent().substring(installPath.length());
      } else {
        testAudioDir = testAudio.getParent();
      }

      return this;
    }
  }
}
