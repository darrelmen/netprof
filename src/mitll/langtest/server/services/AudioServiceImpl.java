/*
 *
 * DISTRIBUTION STATEMENT C. Distribution authorized to U.S. Government Agencies
 * and their contractors; 2015. Other request for this document shall be referred
 * to DLIFLC.
 *
 * WARNING: This document may contain technical data whose export is restricted
 * by the Arms Export Control Act (AECA) or the Export Administration Act (EAA).
 * Transfer of this data by any means to a non-US person who is not eligible to
 * obtain export-controlled data is prohibited. By accepting this data, the consignee
 * agrees to honor the requirements of the AECA and EAA. DESTRUCTION NOTICE: For
 * unclassified, limited distribution documents, destroy by any method that will
 * prevent disclosure of the contents or reconstruction of the document.
 *
 * This material is based upon work supported under Air Force Contract No.
 * FA8721-05-C-0002 and/or FA8702-15-D-0001. Any opinions, findings, conclusions
 * or recommendations expressed in this material are those of the author(s) and
 * do not necessarily reflect the views of the U.S. Air Force.
 *
 * Â© 2015 Massachusetts Institute of Technology.
 *
 * The software/firmware is provided to you on an As-Is basis
 *
 * Delivered to the US Government with Unlimited Rights, as defined in DFARS
 * Part 252.227-7013 or 7014 (Feb 2014). Notwithstanding any copyright notice,
 * U.S. Government rights in this work are defined by DFARS 252.227-7013 or
 * DFARS 252.227-7014 as detailed above. Use of this work other than as specifically
 * authorized by the U.S. Government may violate any copyrights that exist in this work.
 *
 *
 */

package mitll.langtest.server.services;

import audio.image.ImageType;
import audio.imagewriter.SimpleImageWriter;
import mitll.langtest.client.AudioTag;
import mitll.langtest.client.services.AudioService;
import mitll.langtest.server.audio.*;
import mitll.langtest.server.database.AnswerInfo;
import mitll.langtest.server.database.custom.IUserListManager;
import mitll.langtest.shared.answer.AudioAnswer;
import mitll.langtest.shared.answer.AudioType;
import mitll.langtest.shared.exercise.*;
import mitll.langtest.shared.image.ImageResponse;
import mitll.langtest.shared.scoring.AudioContext;
import mitll.langtest.shared.scoring.ImageOptions;
import mitll.langtest.shared.user.User;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;

import java.io.File;

/**
 * does image generation here too - since it's done from a file.
 */
@SuppressWarnings("serial")
public class AudioServiceImpl extends MyRemoteServiceServlet implements AudioService {
  private static final Logger logger = LogManager.getLogger(AudioServiceImpl.class);

  private static final String WAV1 = "wav";
  private static final String WAV = ".wav";
  private static final String MP3 = ".mp3";
  private static final int MP3_LENGTH = MP3.length();

  private static final boolean DEBUG = false;
  private static final boolean WARN_MISSING_FILE = true;

  private AudioConversion audioConversion;
  private PathWriter pathWriter;

  @Override
  public void init() {
    super.init();
    audioConversion = new AudioConversion(serverProps);
    pathWriter = new PathWriter(serverProps);
  }

  /**
   * Record an answer entry in the database.<br></br>
   * Write the posted data to a wav and an mp3 file (since all the browser audio works with mp3).
   * <p>
   * A side effect is to set the first state to UNSET if it was APPROVED
   * and to set the second state (not really used right now) to RECORDED
   * <p>
   * <p>
   * Wade has observed that audio normalization really messes up the ASR -- silence doesn't appear as silence after you multiply
   * the signal.  Also, the user doesn't get feedback that their mic gain is too high/too low or that they
   * are speaking too softly or too loudly
   * <p>
   * Client references below:
   *
   * @param base64EncodedString generated by flash on the client
   * @param recordedWithFlash   mark if we recorded it using flash recorder or webrtc
   * @param deviceType
   * @param device
   * @param doFlashcard         true if called from practice (flashcard) and we want to do decode and not align
   * @param recordInResults     if true, record in results table -- only when recording in a learn or practice tab
   * @param addToAudioTable     if true, add to audio table -- only when recording reference audio for an item.
   * @param allowAlternates
   * @return AudioAnswer object with information about the audio on the server, including if audio is valid (not too short, etc.)
   * @see mitll.langtest.client.scoring.PostAudioRecordButton#stopRecording
   * @see mitll.langtest.client.recorder.RecordButtonPanel#stopRecording
   */
  @Override
  public AudioAnswer writeAudioFile(String base64EncodedString,
                                    AudioContext audioContext,

                                    boolean recordedWithFlash,
                                    String deviceType,
                                    String device,

                                    boolean doFlashcard,
                                    boolean recordInResults,
                                    boolean addToAudioTable,
                                    boolean allowAlternates) {
    int exerciseID = audioContext.getExid();
    boolean isExistingExercise = exerciseID > 0;

    logger.info("writeAudioFile got " +
        "\n\trequest         " + audioContext +
        "\n\tdo flashcard    " + doFlashcard +
        "\n\trecordInResults " + recordInResults +
        "\n\taddToAudioTable " + addToAudioTable +
        "\n\tallowAlternates " + allowAlternates +
        "\n\tpayload bytes   " + base64EncodedString.length());

    boolean amas = serverProps.isAMAS();

    CommonExercise commonExercise = amas || isExistingExercise ?
        db.getCustomOrPredefExercise(getProjectID(), exerciseID) :
        db.getUserExerciseDAO().getTemplateExercise(db.getProjectDAO().getDefault());

    int projid = audioContext.getProjid();
    String language = db.getProject(projid).getLanguage();

    if (!isExistingExercise) {
      ((Exercise) commonExercise).setProjectID(projid);
      audioContext.setExid(commonExercise.getID());
    }

    CommonShell exercise1 = amas ? db.getAMASExercise(exerciseID) : commonExercise;

    if (exercise1 == null && isExistingExercise) {
      logger.warn(getLanguage() + " : couldn't find exerciseID with id '" + exerciseID + "'");
    }
    AnswerInfo.RecordingInfo recordingInfo = new AnswerInfo.RecordingInfo("", "", deviceType, device, recordedWithFlash);

    DecoderOptions options = new DecoderOptions()
        .setRecordInResults(recordInResults)
        .setDoFlashcard(doFlashcard)
        .setRefRecording(addToAudioTable)
        .setAllowAlternates(allowAlternates);

    AudioAnswer audioAnswer = amas ?
        getAudioFileHelper().writeAMASAudioFile(base64EncodedString, db.getAMASExercise(exerciseID), audioContext, recordingInfo) :
        getAudioFileHelper().writeAudioFile(
            base64EncodedString,
            exercise1,
            audioContext, recordingInfo,

            options);

    int user = audioContext.getUserid();
    if (addToAudioTable && audioAnswer.isValid()) {
      audioAnswer.setAudioAttribute(addToAudioTable(user, audioContext.getAudioType(), commonExercise, exerciseID, audioAnswer));
    } //else {
    // So Wade has observed that this really messes up the ASR -- silence doesn't appear as silence after you multiply
    // the signal.  Also, the user doesn't get feedback that their mic gain is too high/too low or that they
    // are speaking too softly or too loudly.

    // normalizeLevel(audioAnswer);
    // }

    if (!audioAnswer.isValid() && audioAnswer.getDurationInMillis() == 0) {
      logger.warn("huh? got zero length recording " + user + " " + exerciseID);
      logEvent("audioRecording", "writeAudioFile", "" + exerciseID, "Writing audio - got zero duration!", user, "unknown", device);
    } else {
      ensureCompressedAudio(user, commonExercise, audioAnswer.getPath(), audioContext.getAudioType(), language);
    }

    return audioAnswer;
  }

  private void ensureCompressedAudio(int user, CommonExercise commonShell, String path, AudioType audioType,
                                     String language) {
    //String foreignLanguage = commonShell == null ? "unknown" : commonShell.getForeignLanguage();
    String userID = getUserID(user);
    if (userID == null) {
      logger.warn("ensureCompressedEquivalent huh? no user for " + user);
    }

    String title = commonShell == null ? "unknown" : commonShell.getForeignLanguage();
    String comment = commonShell == null ? "unknown" : commonShell.getEnglish();
    if (audioType.equals(AudioAttribute.CONTEXT_AUDIO_TYPE) && commonShell != null) {
      if (commonShell.hasContext()) {
        CommonExercise contextSentence = commonShell.getDirectlyRelated().iterator().next();
        title = contextSentence.getForeignLanguage();
        comment = contextSentence.getEnglish();
      }
    }

    ensureMP3(path, new TrackInfo(title, userID, comment, language));
  }

  /**
   * for both audio in answers and best audio -- could be more efficient...
   *
   * @param wavFile
   * @param trackInfo
   * @return true if mp3 file exists
   * @seex #ensureMP3s(CommonExercise, String)
   * @see #writeAudioFile
   */
  private boolean ensureMP3(String wavFile, TrackInfo trackInfo) {
    // if (!wavFile.startsWith(serverProps.getAudioBaseDir()))
    String parent = serverProps.getAnswerDir();
    if (wavFile != null) {
      logger.debug("ensureMP3 : trying " + wavFile);
      // File test = new File(parent + File.separator + language, wavFile);
      File test = new File(wavFile);
      if (!test.exists()) {
        if (WARN_MISSING_FILE) {
          logger.warn("ensureMP3 : can't find " + test.getAbsolutePath());// + " under " + parent + " trying config... ");
        }
        parent = serverProps.getAudioBaseDir();// + File.separator + language;
        logger.warn("ensureMP3 : trying " + wavFile + " under " + parent);// + " under " + parent + " trying config... ");
      }

/*      if (!audioConversion.exists(wavFile, parent)) {// && wavFile.contains("1310")) {
        if (WARN_MISSING_FILE && spew++ < 10) {
          logger.error("ensureMP3 : can't find " + wavFile + " under " + parent + " for " + title + " " + artist);
        }
      }*/

      String s = audioConversion.ensureWriteMP3(wavFile, parent, false, trackInfo);
      boolean isMissing = s.equals(AudioConversion.FILE_MISSING);
      if (isMissing) {
        logger.error("ensureMP3 : can't find " + wavFile + " under " + parent + " for " + trackInfo);
      }
      return !isMissing;
    }
    return false;
  }

  private String getUserID(int user) {
    User userBy = getUserBy(user);
    return userBy == null ? "" + user : userBy.getUserID();
  }

  private User getUserBy(int id) {
    return db.getUserDAO().getUserWhere(id);
  }

  public void logEvent(String id, String widgetType, String exid, String context, int userid, String hitID, String device) {
    try {
      db.logEvent(id, widgetType, exid, context, userid, device);
    } catch (Exception e) {
      logger.error("got " + e, e);
    }
  }

  /**
   * Remember this audio as reference audio for this exercise, and possibly clear the APRROVED (inspected) state
   * on the exercise indicating it needs to be inspected again (we've added new audio).
   * <p>
   * Don't return a path to the normalized audio, since this doesn't let the recorder have feedback about how soft
   * or loud they are : https://gh.ll.mit.edu/DLI-LTEA/Development/issues/601
   *
   * @param user        who recorded audio
   * @param audioType   regular or slow
   * @param exercise1   for which exercise - how could this be null?
   * @param exerciseID  perhaps sometimes we want to override the exercise id?
   * @param audioAnswer holds the path of the temporary recorded file
   * @return AudioAttribute that represents the audio that has been added to the exercise
   * @see #writeAudioFile
   */
  private AudioAttribute addToAudioTable(int user,
                                         AudioType audioType,
                                         CommonExercise exercise1,
                                         int exerciseID,
                                         AudioAnswer audioAnswer) {
    boolean noExistingExercise = exercise1 == null;
    int idToUse = noExistingExercise ? exerciseID : exercise1.getID();
    int projid = noExistingExercise ? -1 : exercise1.getProjectID();
    String audioTranscript = getAudioTranscript(audioType, exercise1);
    String language = db.getProject(projid).getLanguage();
    //   logger.debug("addToAudioTable user " + user + " ex " + exerciseID + " for " + audioType + " path before " + audioAnswer.getPath());

    File absoluteFile = pathHelper.getAbsoluteAudioFile(audioAnswer.getPath());
    boolean isContext = audioType == AudioType.CONTEXT_REGULAR || audioType == AudioType.CONTEXT_SLOW;
    String context = noExistingExercise ? "" :
        isContext ? exercise1.getDirectlyRelated().iterator().next().getEnglish() : exercise1.getEnglish();

    if (!absoluteFile.exists()) logger.error("addToAudioTable huh? no file at " + absoluteFile.getAbsolutePath());
    String permanentAudioPath = pathWriter.
        getPermanentAudioPath(
            absoluteFile,
            getPermanentName(user, audioType),
            true,
            language,
            idToUse,
            //audioTranscript,
            serverProps,
            new TrackInfo(audioTranscript, getArtist(user), context, language));

    AudioAttribute audioAttribute =
        db.getAudioDAO().addOrUpdate(user, idToUse, projid, audioType, permanentAudioPath, System.currentTimeMillis(),
            audioAnswer.getDurationInMillis(), audioTranscript, (float) audioAnswer.getDynamicRange());
    audioAnswer.setPath(audioAttribute.getAudioRef());
    logger.debug("addToAudioTable" +
        "\n\tuser " + user +
        "\n\tex " + exerciseID + "/" + idToUse +
        "\n\tfor " + audioType +
        "\n\taudio answer has " + audioAttribute);

    // what state should we mark recorded audio?
    setExerciseState(idToUse, user, exercise1);
    return audioAttribute;
  }

  private String getAudioTranscript(AudioType audioType, CommonExercise exercise1) {
    return exercise1 == null ? "" :
        audioType.equals(AudioAttribute.CONTEXT_AUDIO_TYPE) ? exercise1.getContext() : exercise1.getForeignLanguage();
  }

  private String getPermanentName(int user, AudioType audioType) {
    return audioType.toString() + "_" + System.currentTimeMillis() + "_by_" + user + ".wav";
  }

  private String getArtist(int user) {
    User userWhere = db.getUserDAO().getUserWhere(user);
    return userWhere == null ? "" + user : userWhere.getUserID();
  }

  private File getAbsoluteFile(String path) {
    return pathHelper.getAbsoluteFile(path);
  }

  /**
   * Only change APPROVED to UNSET.
   *
   * @param exercise
   * @param user
   * @param exercise1
   */
  private void setExerciseState(int exercise, int user, Shell exercise1) {
    if (exercise1 != null) {
      IUserListManager userListManager = getUserListManager();
      STATE currentState = userListManager.getCurrentState(exercise);
      if (currentState == STATE.APPROVED) { // clear approved on new audio -- we need to review it again
        userListManager.setState(exercise1, STATE.UNSET, user);
      }
      userListManager.setSecondState(exercise1, STATE.RECORDED, user);
    }
  }

  IUserListManager getUserListManager() {
    return db.getUserListManager();
  }

/*
  private AudioFileHelper getAudioFileHelper() {
    if (serverProps.isAMAS()) {
      return audioFileHelper;
    } else {
      Project project = getProject();
      if (project == null) {
        logger.warn("getAudioFileHelper no current project???");
        return null;
      }
      return project.getAudioFileHelper();
    }
  }
*/

  /**
   * Get an image of desired dimensions for the audio file - only for Waveform and spectrogram.
   * Also returns the audio file duration -- so we can deal with the difference in length between mp3 and wav
   * versions of the same audio file.  (The browser soundmanager plays mp3 and reports audio offsets into
   * the mp3 file, but all the images are generated from the shorter wav file.)
   * <p>
   * TODO : Worrying about absolute vs relative path is maddening.  Must be a better way!
   *
   * @param reqid
   * @param audioFile
   * @param imageType
   * @param imageOptions
   * @param exerciseID
   * @return path to an image file
   * @see mitll.langtest.client.scoring.AudioPanel#getImageURLForAudio
   */
  public ImageResponse getImageForAudioFile(int reqid,
                                            String audioFile,
                                            String imageType,
                                            ImageOptions imageOptions,
                                            String exerciseID) {
    if (audioFile.isEmpty()) logger.error("getImageForAudioFile huh? audio file is empty for req id " + reqid + " exid " + exerciseID);

    SimpleImageWriter imageWriter = new SimpleImageWriter();

    String wavAudioFile = getWavAudioFile(audioFile);
    File testFile = new File(wavAudioFile);
    if (!testFile.exists() || testFile.length() == 0) {
      if (testFile.length() == 0) logger.error("getImageForAudioFile : huh? " + wavAudioFile + " is empty???");
      return new ImageResponse();
    }
    ImageType imageType1 =
        imageType.equalsIgnoreCase(ImageType.WAVEFORM.toString()) ? ImageType.WAVEFORM :
            imageType.equalsIgnoreCase(ImageType.SPECTROGRAM.toString()) ? ImageType.SPECTROGRAM : null;
    if (imageType1 == null) {
      logger.error("getImageForAudioFile '" + imageType + "' is unknown?");
      return new ImageResponse(); // success = false!
    }
//    if (DEBUG || true) {
//      logger.debug("getImageForAudioFile : getting images (" + width + " x " + height + ") (" + reqid + ") type " + imageType +
//          " for " + wavAudioFile + "");
//    }

    long then = System.currentTimeMillis();

    String absolutePathToImage = imageWriter.writeImage(
        wavAudioFile,
        getAbsoluteFile(pathHelper.getImageOutDir()).getAbsolutePath(),
        imageOptions.getWidth(), imageOptions.getHeight(), imageType1, exerciseID);
    long now = System.currentTimeMillis();
    long diff = now - then;
    if (diff > 100) {
      logger.debug("getImageForAudioFile : got images " +
         // "(" + width + " x " + height + ")" +
          " (" + reqid + ") type " + imageType +
          " for " + wavAudioFile + " took " + diff + " millis");
    }
    String installPath = pathHelper.getInstallPath();

    String relativeImagePath = absolutePathToImage;
    if (absolutePathToImage.startsWith(installPath)) {
      relativeImagePath = absolutePathToImage.substring(installPath.length());
    } else {
      logger.error("getImageForAudioFile huh? file path " + absolutePathToImage + " doesn't start with " + installPath + "?");
    }

    relativeImagePath = pathHelper.ensureForwardSlashes(relativeImagePath);
    if (relativeImagePath.startsWith("/")) {
      relativeImagePath = relativeImagePath.substring(1);
    }
    String imageURL = relativeImagePath;
    double duration = new AudioCheck(serverProps).getDurationInSeconds(wavAudioFile);
    if (duration == 0) {
      logger.error("huh? " + wavAudioFile + " has zero duration???");
    }
    /*    logger.debug("for " + wavAudioFile + " type " + imageType + " rel path is " + relativeImagePath +
        " url " + imageURL + " duration " + duration);*/

    return new ImageResponse(reqid, imageURL, duration);
  }

  /**
   * Here we assume the audioFile path is like
   * <p>
   * bestAudio/spanish/bestAudio/123/regular_xxx.mp3
   * OR answers/spanish/answers/123/regular_xxx.mp3
   *
   * @param audioFile
   * @return
   */
  private String getWavAudioFile(String audioFile) {
    if (audioFile.endsWith("." + AudioTag.COMPRESSED_TYPE) || audioFile.endsWith(MP3)) {
      String wavFile = removeSuffix(audioFile) + WAV;
      logger.info("getWavAudioFile " + audioFile);
      if (new File(wavFile).exists()) {
        return wavFile;
      } else {
        File test = pathHelper.getAbsoluteAudioFile(wavFile);
        logger.info("getWavAudioFile test " + test.getAbsolutePath());

        audioFile = test.exists() ? test.getAbsolutePath() : "FILE_MISSING.wav";//getAudioFileHelper().getWavForMP3(audioFile, );
      }
    }

    return ensureWAV(audioFile);
  }

  private String removeSuffix(String audioFile) {
    return audioFile.substring(0, audioFile.length() - MP3_LENGTH);
  }

  private String ensureWAV(String audioFile) {
    if (!audioFile.endsWith(WAV1)) {
      return audioFile.substring(0, audioFile.length() - MP3_LENGTH) + WAV;
    } else {
      return audioFile;
    }
  }

  /**
   * Put the new item in the database,
   * copy the audio under bestAudio
   * assign the item to a user list
   * <p>
   * So here we set the exercise id to the final id, not a provisional id, as assigned earlier.
   *
   * @param userListID
   * @param userExercise
   * @param language
   * @see mitll.langtest.client.custom.dialog.NewUserExercise#afterValidForeignPhrase
   */
  @Override
  public CommonExercise reallyCreateNewItem(long userListID, CommonExercise userExercise, String language) {
    if (DEBUG) logger.debug("reallyCreateNewItem : made user exercise " + userExercise + " on list " + userListID);
    getUserListManager().reallyCreateNewItem(userListID, userExercise, serverProps.getMediaDir());
    int id = userExercise.getID();

    for (AudioAttribute audioAttribute : userExercise.getAudioAttributes()) {
      if (DEBUG) logger.debug("\treallyCreateNewItem : update " + audioAttribute + " to " + id);
      db.getAudioDAO().updateExerciseID(
          audioAttribute.getUniqueID(),
          id,
          audioAttribute.getAudioRef());
    }
    if (DEBUG) logger.debug("\treallyCreateNewItem : made user exercise " + userExercise + " on list " + userListID);

    return userExercise;
  }
}